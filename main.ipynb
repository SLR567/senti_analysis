{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1697e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from util import readExamples, evaluatePredictor\n",
    "from model import extractFeatures, learnPredictor, plot_loss\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add332b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0a31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b62471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(numIters, eta, reg, mode, train_data, test_data, train_label, test_label):\n",
    "    #train_set = readExamples('data/data_rt.train')\n",
    "    #train_new = []\n",
    "    #for example in train_set:\n",
    "        #text = normalize_string(example[0])\n",
    "        #label = example[1]\n",
    "        #train_new.append((text, label))\n",
    "\n",
    "    \n",
    "    #train_corpus = [example[0] for example in train_new]\n",
    "    \n",
    "    #train_label = [example[1] for example in train_new]\n",
    "   \n",
    "    #train_embed = extractFeatures(train_corpus, mode)\n",
    "    \n",
    "    #train_data, val_data, train_l, val_l = train_test_split(train_embed, train_label, test_size = 0.1, random_state = 31)\n",
    "    weight, bias, training_loss, test_error_list = learnPredictor(train_data, test_data, train_label, test_label, numIters=numIters, eta=eta, reg = reg)\n",
    "    \n",
    "    plot_loss(training_loss, 'train', mode, eta)\n",
    "    plot_loss(test_error_list, 'test', mode, eta)\n",
    "\n",
    "    trainError = evaluatePredictor(train_data, train_label, weight, bias)\n",
    "    testError = evaluatePredictor(test_data, test_label, weight, bias)\n",
    "    \n",
    "    print (\"training error = %s, test error = %s\" % (trainError, testError))\n",
    "    return weight, bias, testError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628609a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0000184732510105\n",
      "training loss at 5000 is: 0.9647835402087905\n",
      "training error at 5000 is: 0.18908272369161508\n",
      "test error at 5000 is: 0.29487900956668545\n",
      "current test loss is: 0.958157189905375\n",
      "training loss at 10000 is: 0.8910441937043544\n",
      "training error at 10000 is: 0.18007878446820483\n",
      "test error at 10000 is: 0.2763083849184018\n",
      "current test loss is: 0.9146462344369057\n",
      "training loss at 15000 is: 0.825406851486149\n",
      "training error at 15000 is: 0.17332583005064717\n",
      "test error at 15000 is: 0.2734946539110861\n",
      "current test loss is: 0.8726463865197506\n",
      "training loss at 20000 is: 0.7375710989101162\n",
      "training error at 20000 is: 0.17248171074845245\n",
      "test error at 20000 is: 0.27152504220596513\n",
      "current test loss is: 0.8315577351555264\n",
      "training loss at 25000 is: 0.6857052915732115\n",
      "training error at 25000 is: 0.1671356218345526\n",
      "test error at 25000 is: 0.26814856499718626\n",
      "current test loss is: 0.7984570679964674\n",
      "training loss at 30000 is: 0.6389009132255656\n",
      "training error at 30000 is: 0.1637591446257738\n",
      "test error at 30000 is: 0.26814856499718626\n",
      "current test loss is: 0.7705275185893607\n",
      "training loss at 35000 is: 0.5890523425370665\n",
      "training error at 35000 is: 0.15531795160382666\n",
      "test error at 35000 is: 0.26533483398987057\n",
      "current test loss is: 0.7486871684876427\n",
      "training loss at 40000 is: 0.5577911442571518\n",
      "training error at 40000 is: 0.14715813168261113\n",
      "test error at 40000 is: 0.26477208778840744\n",
      "current test loss is: 0.7312958474604697\n",
      "training loss at 45000 is: 0.5192194905443321\n",
      "training error at 45000 is: 0.14209341586944288\n",
      "test error at 45000 is: 0.2625211029825549\n",
      "current test loss is: 0.7173356012539247\n",
      "training loss at 50000 is: 0.49982650197231276\n",
      "training error at 50000 is: 0.13224535734383794\n",
      "test error at 50000 is: 0.26139561057962857\n",
      "current test loss is: 0.705080412382526\n",
      "training loss at 55000 is: 0.47926013740307827\n",
      "training error at 55000 is: 0.12605514912774338\n",
      "test error at 55000 is: 0.26083286437816544\n",
      "current test loss is: 0.6960934968598312\n",
      "training loss at 60000 is: 0.44302878344129315\n",
      "training error at 60000 is: 0.12324141812042769\n",
      "test error at 60000 is: 0.2597073719752392\n",
      "current test loss is: 0.6885270677303917\n",
      "training loss at 65000 is: 0.4396720127702027\n",
      "training error at 65000 is: 0.118458075407991\n",
      "test error at 65000 is: 0.2557681485649972\n",
      "current test loss is: 0.6817262651973288\n",
      "training loss at 70000 is: 0.4094801142972481\n",
      "training error at 70000 is: 0.11311198649409117\n",
      "test error at 70000 is: 0.25801913337084975\n",
      "current test loss is: 0.6758428141127288\n",
      "training loss at 75000 is: 0.4032707428177263\n",
      "training error at 75000 is: 0.1080472706809229\n",
      "test error at 75000 is: 0.2574563871693866\n",
      "current test loss is: 0.6714536615715413\n",
      "training loss at 80000 is: 0.38219226775321324\n",
      "training error at 80000 is: 0.10467079347214406\n",
      "test error at 80000 is: 0.2566122678671919\n",
      "current test loss is: 0.6664629816585258\n",
      "training loss at 85000 is: 0.3706059756269577\n",
      "training error at 85000 is: 0.10213843556555993\n",
      "test error at 85000 is: 0.25801913337084975\n",
      "current test loss is: 0.6624290713893927\n",
      "training loss at 90000 is: 0.3613677655667962\n",
      "training error at 90000 is: 0.0967923466516601\n",
      "test error at 90000 is: 0.2577377602701182\n",
      "current test loss is: 0.658519900731214\n",
      "training loss at 95000 is: 0.33987488825399303\n",
      "training error at 95000 is: 0.09425998874507598\n",
      "test error at 95000 is: 0.25717501406865506\n",
      "training error = 0.09425998874507598, test error = 0.25717501406865506\n",
      "Test error of BOW is: 0.25717501406865506\n",
      "training error at 0 is: 0.4974676420934159\n",
      "test error at 0 is: 0.4932470455824423\n",
      "current test loss is: 1.0000004741136883\n",
      "training loss at 5000 is: 0.9855413801228627\n",
      "training error at 5000 is: 0.10495216657287564\n",
      "test error at 5000 is: 0.42909397861564436\n",
      "current test loss is: 0.9984618621848784\n",
      "training loss at 10000 is: 0.9559224828655173\n",
      "training error at 10000 is: 0.030669667979741137\n",
      "test error at 10000 is: 0.4167135621834553\n",
      "current test loss is: 0.9967889327882207\n",
      "training loss at 15000 is: 0.9246896074225298\n",
      "training error at 15000 is: 0.010973550928531233\n",
      "test error at 15000 is: 0.4108047270680923\n",
      "current test loss is: 0.9951293942261829\n",
      "training loss at 20000 is: 0.8940135196624558\n",
      "training error at 20000 is: 0.0039392234102419805\n",
      "test error at 20000 is: 0.4105233539673607\n",
      "current test loss is: 0.9934972722825238\n",
      "training loss at 25000 is: 0.8654254124298093\n",
      "training error at 25000 is: 0.0033764772087788407\n",
      "test error at 25000 is: 0.4099606077658976\n",
      "current test loss is: 0.9917838166311984\n",
      "training loss at 30000 is: 0.8337770762572924\n",
      "training error at 30000 is: 0.0033764772087788407\n",
      "test error at 30000 is: 0.41024198086662916\n",
      "current test loss is: 0.9900273177129211\n",
      "training loss at 35000 is: 0.8047993496001254\n",
      "training error at 35000 is: 0.0025323579065841305\n",
      "test error at 35000 is: 0.40827236916150816\n",
      "current test loss is: 0.9883335716530903\n",
      "training loss at 40000 is: 0.7759159836196281\n",
      "training error at 40000 is: 0.0016882386043894203\n",
      "test error at 40000 is: 0.4054586381541925\n",
      "current test loss is: 0.9866903642514324\n",
      "training loss at 45000 is: 0.7463011326102393\n",
      "training error at 45000 is: 0.0016882386043894203\n",
      "test error at 45000 is: 0.40630275745638716\n",
      "current test loss is: 0.984924557892654\n",
      "training loss at 50000 is: 0.713559437381923\n",
      "training error at 50000 is: 0.0011254924029262803\n",
      "test error at 50000 is: 0.4099606077658976\n",
      "current test loss is: 0.983305415150163\n",
      "training loss at 55000 is: 0.6845573054851923\n",
      "training error at 55000 is: 0.0014068655036578502\n",
      "test error at 55000 is: 0.4079909960607766\n",
      "current test loss is: 0.9815937426672016\n",
      "training loss at 60000 is: 0.6569830411720774\n",
      "training error at 60000 is: 0.0014068655036578502\n",
      "test error at 60000 is: 0.4093978615644344\n",
      "current test loss is: 0.9800422284515975\n",
      "training loss at 65000 is: 0.6277711971014697\n",
      "training error at 65000 is: 0.0014068655036578502\n",
      "test error at 65000 is: 0.40967923466516604\n",
      "current test loss is: 0.9784594228765459\n",
      "training loss at 70000 is: 0.5966295331640735\n",
      "training error at 70000 is: 0.0014068655036578502\n",
      "test error at 70000 is: 0.4079909960607766\n",
      "training error = 0.0014068655036578502, test error = 0.4079909960607766\n",
      "Test error of Bigram is: 0.4079909960607766\n",
      "training error at 0 is: 0.49774901519414744\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9864750770941031\n",
      "training error at 5000 is: 0.12661789532920653\n",
      "test error at 5000 is: 0.48339898705683737\n",
      "current test loss is: 0.9998584084922916\n",
      "training loss at 10000 is: 0.9578403238941974\n",
      "training error at 10000 is: 0.03939223410241981\n",
      "test error at 10000 is: 0.48283624085537424\n",
      "current test loss is: 0.9997449703748253\n",
      "training loss at 15000 is: 0.9312301405838698\n",
      "training error at 15000 is: 0.016882386043894203\n",
      "test error at 15000 is: 0.48171074845244793\n",
      "current test loss is: 0.999592754487603\n",
      "training loss at 20000 is: 0.9027739218340581\n",
      "training error at 20000 is: 0.009848058525604952\n",
      "test error at 20000 is: 0.4800225098480585\n",
      "current test loss is: 0.9994597626754357\n",
      "training loss at 25000 is: 0.8765159985408322\n",
      "training error at 25000 is: 0.009285312324141813\n",
      "test error at 25000 is: 0.47945976364659537\n",
      "current test loss is: 0.9993478680527178\n",
      "training loss at 30000 is: 0.8487366440824479\n",
      "training error at 30000 is: 0.009285312324141813\n",
      "test error at 30000 is: 0.47974113674732694\n",
      "current test loss is: 0.9992412731515297\n",
      "training loss at 35000 is: 0.8201337001465896\n",
      "training error at 35000 is: 0.009566685424873381\n",
      "test error at 35000 is: 0.47974113674732694\n",
      "current test loss is: 0.999149785645761\n",
      "training loss at 40000 is: 0.792234775462111\n",
      "training error at 40000 is: 0.009566685424873381\n",
      "test error at 40000 is: 0.47945976364659537\n",
      "current test loss is: 0.9990360668848854\n",
      "training loss at 45000 is: 0.765129824033926\n",
      "training error at 45000 is: 0.009285312324141813\n",
      "test error at 45000 is: 0.47945976364659537\n",
      "current test loss is: 0.998926913440572\n",
      "training loss at 50000 is: 0.7373555484509986\n",
      "training error at 50000 is: 0.009285312324141813\n",
      "test error at 50000 is: 0.47945976364659537\n",
      "current test loss is: 0.9988193597520775\n",
      "training loss at 55000 is: 0.7083807527530053\n",
      "training error at 55000 is: 0.009285312324141813\n",
      "test error at 55000 is: 0.47974113674732694\n",
      "current test loss is: 0.998702753913321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 60000 is: 0.683331031828566\n",
      "training error at 60000 is: 0.009285312324141813\n",
      "test error at 60000 is: 0.47945976364659537\n",
      "current test loss is: 0.9985799859394887\n",
      "training loss at 65000 is: 0.6563936201625825\n",
      "training error at 65000 is: 0.009285312324141813\n",
      "test error at 65000 is: 0.47945976364659537\n",
      "current test loss is: 0.9984979845939056\n",
      "training loss at 70000 is: 0.6267991057900906\n",
      "training error at 70000 is: 0.009285312324141813\n",
      "test error at 70000 is: 0.47945976364659537\n",
      "current test loss is: 0.9984109615748274\n",
      "training loss at 75000 is: 0.6003520035963505\n",
      "training error at 75000 is: 0.009285312324141813\n",
      "test error at 75000 is: 0.4800225098480585\n",
      "current test loss is: 0.9982840515887953\n",
      "training loss at 80000 is: 0.568982564261847\n",
      "training error at 80000 is: 0.009285312324141813\n",
      "test error at 80000 is: 0.47974113674732694\n",
      "current test loss is: 0.9981619823679959\n",
      "training loss at 85000 is: 0.5429031631206188\n",
      "training error at 85000 is: 0.009285312324141813\n",
      "test error at 85000 is: 0.47974113674732694\n",
      "current test loss is: 0.998046156727552\n",
      "training loss at 90000 is: 0.5169490931971233\n",
      "training error at 90000 is: 0.009285312324141813\n",
      "test error at 90000 is: 0.47974113674732694\n",
      "current test loss is: 0.9979059956150446\n",
      "training loss at 95000 is: 0.49003578640453727\n",
      "training error at 95000 is: 0.009285312324141813\n",
      "test error at 95000 is: 0.47974113674732694\n",
      "current test loss is: 0.9977808384701378\n",
      "training loss at 100000 is: 0.4613138215129777\n",
      "training error at 100000 is: 0.009285312324141813\n",
      "test error at 100000 is: 0.47974113674732694\n",
      "training error = 0.009285312324141813, test error = 0.47974113674732694\n",
      "Test error of Trigram is: 0.47974113674732694\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 0.9999995977240269\n",
      "training loss at 5000 is: 0.9799144582341082\n",
      "training error at 5000 is: 0.09482273494653912\n",
      "test error at 5000 is: 0.291221159257175\n",
      "current test loss is: 0.9884214781234238\n",
      "training loss at 10000 is: 0.9410199763378032\n",
      "training error at 10000 is: 0.058244231851435\n",
      "test error at 10000 is: 0.2782779966235228\n",
      "current test loss is: 0.9771508587724429\n",
      "training loss at 15000 is: 0.9009166408165965\n",
      "training error at 15000 is: 0.05205402363534046\n",
      "test error at 15000 is: 0.27743387732132807\n",
      "current test loss is: 0.9657928137167334\n",
      "training loss at 20000 is: 0.8617318237898574\n",
      "training error at 20000 is: 0.04164321890827237\n",
      "test error at 20000 is: 0.2687113111986494\n",
      "current test loss is: 0.9542045620964401\n",
      "training loss at 25000 is: 0.8218615781283611\n",
      "training error at 25000 is: 0.04023635340461452\n",
      "test error at 25000 is: 0.2664603263927969\n",
      "current test loss is: 0.9428093490726104\n",
      "training loss at 30000 is: 0.7820901850518652\n",
      "training error at 30000 is: 0.03545301069217783\n",
      "test error at 30000 is: 0.2678671918964547\n",
      "current test loss is: 0.9315800341469637\n",
      "training loss at 35000 is: 0.7360656427623492\n",
      "training error at 35000 is: 0.03460889138998312\n",
      "test error at 35000 is: 0.2703995498030388\n",
      "current test loss is: 0.9198483004665441\n",
      "training loss at 40000 is: 0.6996526956473356\n",
      "training error at 40000 is: 0.03460889138998312\n",
      "test error at 40000 is: 0.2723691615081598\n",
      "current test loss is: 0.908258117685765\n",
      "training loss at 45000 is: 0.6684693588255619\n",
      "training error at 45000 is: 0.031232414181204277\n",
      "test error at 45000 is: 0.2687113111986494\n",
      "current test loss is: 0.8976448634276618\n",
      "training loss at 50000 is: 0.6295181193199921\n",
      "training error at 50000 is: 0.030669667979741137\n",
      "test error at 50000 is: 0.2706809229037704\n",
      "current test loss is: 0.8872732616448804\n",
      "training loss at 55000 is: 0.5904408417381914\n",
      "training error at 55000 is: 0.028137310073157007\n",
      "test error at 55000 is: 0.27096229600450195\n",
      "training error = 0.028137310073157007, test error = 0.27096229600450195\n",
      "Test error of Combo is: 0.27096229600450195\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 0.9984190045453996\n",
      "training loss at 5000 is: 0.9905663317259729\n",
      "training error at 5000 is: 0.48227349465391106\n",
      "test error at 5000 is: 0.4684862127180642\n",
      "current test loss is: 0.965179036713634\n",
      "training loss at 10000 is: 0.9743982647218677\n",
      "training error at 10000 is: 0.4569499155880698\n",
      "test error at 10000 is: 0.4355655599324705\n",
      "current test loss is: 0.9377125954623805\n",
      "training loss at 15000 is: 0.96185737273036\n",
      "training error at 15000 is: 0.4485087225661227\n",
      "test error at 15000 is: 0.4355655599324705\n",
      "current test loss is: 0.9401979074623534\n",
      "training loss at 20000 is: 0.9795921647630348\n",
      "training error at 20000 is: 0.47974113674732694\n",
      "test error at 20000 is: 0.46539110861001687\n",
      "current test loss is: 0.9389273874046086\n",
      "training loss at 25000 is: 0.9753731901254318\n",
      "training error at 25000 is: 0.4375351716375914\n",
      "test error at 25000 is: 0.4254361283061339\n",
      "current test loss is: 0.9356450072951588\n",
      "training loss at 30000 is: 0.9664063453832396\n",
      "training error at 30000 is: 0.46004501969611705\n",
      "test error at 30000 is: 0.4448508722566123\n",
      "current test loss is: 0.9434503291621341\n",
      "training loss at 35000 is: 0.9717250996770123\n",
      "training error at 35000 is: 0.4597636465953855\n",
      "test error at 35000 is: 0.4442881260551491\n",
      "current test loss is: 0.9439120404240795\n",
      "training loss at 40000 is: 0.958031743683093\n",
      "training error at 40000 is: 0.4786156443444007\n",
      "test error at 40000 is: 0.46482836240855374\n",
      "current test loss is: 0.9399719330145666\n",
      "training loss at 45000 is: 0.965025886048925\n",
      "training error at 45000 is: 0.4465391108610017\n",
      "test error at 45000 is: 0.4355655599324705\n",
      "current test loss is: 0.9407043795817944\n",
      "training loss at 50000 is: 0.9633499975071224\n",
      "training error at 50000 is: 0.44063027574563873\n",
      "test error at 50000 is: 0.42459200900393923\n",
      "current test loss is: 0.9316320485693083\n",
      "training loss at 55000 is: 0.9735497736935588\n",
      "training error at 55000 is: 0.4603263927968486\n",
      "test error at 55000 is: 0.4501969611705121\n",
      "current test loss is: 0.9306204621796228\n",
      "training loss at 60000 is: 0.9634801818063634\n",
      "training error at 60000 is: 0.441755768148565\n",
      "test error at 60000 is: 0.4200900393922341\n",
      "current test loss is: 0.9307338515663546\n",
      "training loss at 65000 is: 0.9518495713843589\n",
      "training error at 65000 is: 0.47692740574001125\n",
      "test error at 65000 is: 0.4625773776027012\n",
      "current test loss is: 0.935770134396956\n",
      "training loss at 70000 is: 0.9594842938196947\n",
      "training error at 70000 is: 0.4952166572875633\n",
      "test error at 70000 is: 0.4943725379853686\n",
      "current test loss is: 0.9806146871400656\n",
      "training loss at 75000 is: 0.9702833557907936\n",
      "training error at 75000 is: 0.4622960045019696\n",
      "test error at 75000 is: 0.4569499155880698\n",
      "current test loss is: 0.9308742739027114\n",
      "training loss at 80000 is: 0.9678409998704914\n",
      "training error at 80000 is: 0.4563871693866066\n",
      "test error at 80000 is: 0.4442881260551491\n",
      "current test loss is: 0.9272202269941189\n",
      "training loss at 85000 is: 0.9575274410123374\n",
      "training error at 85000 is: 0.4954980303882949\n",
      "test error at 85000 is: 0.4946539110861002\n",
      "current test loss is: 1.0093056112605772\n",
      "training loss at 90000 is: 0.9699156700781667\n",
      "training error at 90000 is: 0.45891952729319074\n",
      "test error at 90000 is: 0.44879009566685424\n",
      "training error = 0.45891952729319074, test error = 0.44879009566685424\n",
      "Test error of Word2Vec is: 0.44879009566685424\n",
      "training error at 0 is: 0.5033764772087789\n",
      "test error at 0 is: 0.5\n",
      "current test loss is: 1.000028421936019\n",
      "training loss at 5000 is: 0.8228664294820883\n",
      "training error at 5000 is: 0.19611705120990433\n",
      "test error at 5000 is: 0.2915025323579066\n",
      "current test loss is: 0.801449007195527\n",
      "training loss at 10000 is: 0.5742054971699108\n",
      "training error at 10000 is: 0.15109735509285313\n",
      "test error at 10000 is: 0.26533483398987057\n",
      "current test loss is: 0.7082595919826176\n",
      "training loss at 15000 is: 0.4496835579063529\n",
      "training error at 15000 is: 0.12042768711311198\n",
      "test error at 15000 is: 0.2549240292628025\n",
      "current test loss is: 0.670190232473115\n",
      "training loss at 20000 is: 0.3793701362740141\n",
      "training error at 20000 is: 0.10298255486775464\n",
      "test error at 20000 is: 0.25323579065841306\n",
      "current test loss is: 0.6485179978749915\n",
      "training loss at 25000 is: 0.3208414949456605\n",
      "training error at 25000 is: 0.0855374226223973\n",
      "test error at 25000 is: 0.25267304445694994\n",
      "current test loss is: 0.6350271155204416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 30000 is: 0.27054606880453397\n",
      "training error at 30000 is: 0.07850309510410805\n",
      "test error at 30000 is: 0.2543612830613393\n",
      "current test loss is: 0.6277498605851939\n",
      "training loss at 35000 is: 0.23690704175035904\n",
      "training error at 35000 is: 0.06555993247045583\n",
      "test error at 35000 is: 0.2537985368598762\n",
      "current test loss is: 0.6222566461606024\n",
      "training loss at 40000 is: 0.20865503895683793\n",
      "training error at 40000 is: 0.05965109735509285\n",
      "test error at 40000 is: 0.25239167135621837\n",
      "current test loss is: 0.6213737669812701\n",
      "training loss at 45000 is: 0.19564696018746894\n",
      "training error at 45000 is: 0.050365785030951044\n",
      "test error at 45000 is: 0.2585818795723129\n",
      "current test loss is: 0.6204839784331896\n",
      "training loss at 50000 is: 0.1670898687238448\n",
      "training error at 50000 is: 0.04614518851997749\n",
      "test error at 50000 is: 0.2597073719752392\n",
      "current test loss is: 0.6184055868000949\n",
      "training loss at 55000 is: 0.14842204413715915\n",
      "training error at 55000 is: 0.04276871131119865\n",
      "test error at 55000 is: 0.261114237478897\n",
      "current test loss is: 0.6193276913152693\n",
      "training loss at 60000 is: 0.13793602680955902\n",
      "training error at 60000 is: 0.037985368598761955\n",
      "test error at 60000 is: 0.263083849184018\n",
      "current test loss is: 0.6195493761652406\n",
      "training loss at 65000 is: 0.13431639042701723\n",
      "training error at 65000 is: 0.032639279684862126\n",
      "test error at 65000 is: 0.26364659538548113\n",
      "current test loss is: 0.620078086735424\n",
      "training loss at 70000 is: 0.12054270744267624\n",
      "training error at 70000 is: 0.030106921778277996\n",
      "test error at 70000 is: 0.2644907146876759\n",
      "training error = 0.030106921778277996, test error = 0.2644907146876759\n",
      "Test error of BOW is: 0.2644907146876759\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9256361297222906\n",
      "training error at 5000 is: 0.10467079347214406\n",
      "test error at 5000 is: 0.411648846370287\n",
      "current test loss is: 0.9910909546106914\n",
      "training loss at 10000 is: 0.775807191091897\n",
      "training error at 10000 is: 0.028418683173888577\n",
      "test error at 10000 is: 0.40770962296004504\n",
      "current test loss is: 0.9823607242639092\n",
      "training loss at 15000 is: 0.6246804563947747\n",
      "training error at 15000 is: 0.011536297129994372\n",
      "test error at 15000 is: 0.40827236916150816\n",
      "current test loss is: 0.9741443285796937\n",
      "training loss at 20000 is: 0.47848398437772255\n",
      "training error at 20000 is: 0.0061902082160945416\n",
      "test error at 20000 is: 0.40574001125492404\n",
      "current test loss is: 0.9672669017706431\n",
      "training loss at 25000 is: 0.3567314172845022\n",
      "training error at 25000 is: 0.0036578503095104106\n",
      "test error at 25000 is: 0.40574001125492404\n",
      "current test loss is: 0.9623331088156046\n",
      "training loss at 30000 is: 0.24589847850885543\n",
      "training error at 30000 is: 0.0016882386043894203\n",
      "test error at 30000 is: 0.40433314575126617\n",
      "current test loss is: 0.9582222353480122\n",
      "training loss at 35000 is: 0.15975842953115643\n",
      "training error at 35000 is: 0.0011254924029262803\n",
      "test error at 35000 is: 0.40574001125492404\n",
      "current test loss is: 0.9552409706482767\n",
      "training loss at 40000 is: 0.10284455660549081\n",
      "training error at 40000 is: 0.0014068655036578502\n",
      "test error at 40000 is: 0.4060213843556556\n",
      "current test loss is: 0.9539000771265101\n",
      "training loss at 45000 is: 0.06463822242537115\n",
      "training error at 45000 is: 0.0011254924029262803\n",
      "test error at 45000 is: 0.40574001125492404\n",
      "current test loss is: 0.9528590515737497\n",
      "training loss at 50000 is: 0.03702417456218042\n",
      "training error at 50000 is: 0.0011254924029262803\n",
      "test error at 50000 is: 0.40292628024760835\n",
      "current test loss is: 0.9522301799885918\n",
      "training loss at 55000 is: 0.02268101078871339\n",
      "training error at 55000 is: 0.0011254924029262803\n",
      "test error at 55000 is: 0.4034890264490715\n",
      "current test loss is: 0.951875949134731\n",
      "training loss at 60000 is: 0.013165313686497515\n",
      "training error at 60000 is: 0.0011254924029262803\n",
      "test error at 60000 is: 0.40377039954980304\n",
      "current test loss is: 0.9515916522697306\n",
      "training loss at 65000 is: 0.008881551161515911\n",
      "training error at 65000 is: 0.0011254924029262803\n",
      "test error at 65000 is: 0.4054586381541925\n",
      "current test loss is: 0.9514742296374274\n",
      "training loss at 70000 is: 0.00422392186484317\n",
      "training error at 70000 is: 0.0011254924029262803\n",
      "test error at 70000 is: 0.4051772650534609\n",
      "current test loss is: 0.9514146238945824\n",
      "training loss at 75000 is: 0.004786839947396725\n",
      "training error at 75000 is: 0.0011254924029262803\n",
      "test error at 75000 is: 0.4040517726505346\n",
      "current test loss is: 0.9512360318936323\n",
      "training loss at 80000 is: 0.005248830892611447\n",
      "training error at 80000 is: 0.0011254924029262803\n",
      "test error at 80000 is: 0.40461451885199773\n",
      "training error = 0.0011254924029262803, test error = 0.40461451885199773\n",
      "Test error of Bigram is: 0.40461451885199773\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9313423013821585\n",
      "training error at 5000 is: 0.12549240292628025\n",
      "test error at 5000 is: 0.48227349465391106\n",
      "current test loss is: 0.9994874928547767\n",
      "training loss at 10000 is: 0.7951065920376986\n",
      "training error at 10000 is: 0.032357906584130555\n",
      "test error at 10000 is: 0.4805852560495217\n",
      "current test loss is: 0.9989195120970383\n",
      "training loss at 15000 is: 0.6540091481712771\n",
      "training error at 15000 is: 0.015194147439504783\n",
      "test error at 15000 is: 0.48086662915025324\n",
      "current test loss is: 0.9981938413351105\n",
      "training loss at 20000 is: 0.5169977489886525\n",
      "training error at 20000 is: 0.010129431626336522\n",
      "test error at 20000 is: 0.4805852560495217\n",
      "current test loss is: 0.9976407626298802\n",
      "training loss at 25000 is: 0.3884945558594165\n",
      "training error at 25000 is: 0.009566685424873381\n",
      "test error at 25000 is: 0.47974113674732694\n",
      "current test loss is: 0.9972713595009415\n",
      "training loss at 30000 is: 0.2769389083220974\n",
      "training error at 30000 is: 0.009285312324141813\n",
      "test error at 30000 is: 0.4791783905458638\n",
      "current test loss is: 0.9969026143411295\n",
      "training loss at 35000 is: 0.18383159594864742\n",
      "training error at 35000 is: 0.009285312324141813\n",
      "test error at 35000 is: 0.47945976364659537\n",
      "current test loss is: 0.9965797919765925\n",
      "training loss at 40000 is: 0.12234347238599912\n",
      "training error at 40000 is: 0.009285312324141813\n",
      "test error at 40000 is: 0.47974113674732694\n",
      "current test loss is: 0.9963410930975231\n",
      "training loss at 45000 is: 0.07744568855970535\n",
      "training error at 45000 is: 0.009285312324141813\n",
      "test error at 45000 is: 0.47945976364659537\n",
      "current test loss is: 0.9961777418618841\n",
      "training loss at 50000 is: 0.050810064069735476\n",
      "training error at 50000 is: 0.009285312324141813\n",
      "test error at 50000 is: 0.47974113674732694\n",
      "current test loss is: 0.996112347056531\n",
      "training loss at 55000 is: 0.041570987965269285\n",
      "training error at 55000 is: 0.009285312324141813\n",
      "test error at 55000 is: 0.47974113674732694\n",
      "current test loss is: 0.9960953081606545\n",
      "training loss at 60000 is: 0.0321794248011111\n",
      "training error at 60000 is: 0.009285312324141813\n",
      "test error at 60000 is: 0.47974113674732694\n",
      "training error = 0.009285312324141813, test error = 0.47974113674732694\n",
      "Test error of Trigram is: 0.47974113674732694\n",
      "training error at 0 is: 0.4912774338773213\n",
      "test error at 0 is: 0.4904333145751266\n",
      "current test loss is: 1.0000010913395883\n",
      "training loss at 5000 is: 0.8977918526338935\n",
      "training error at 5000 is: 0.09566685424873382\n",
      "test error at 5000 is: 0.2906584130557119\n",
      "current test loss is: 0.942023971065607\n",
      "training loss at 10000 is: 0.6996098425727753\n",
      "training error at 10000 is: 0.05908835115362971\n",
      "test error at 10000 is: 0.2782779966235228\n",
      "current test loss is: 0.8871068136816982\n",
      "training loss at 15000 is: 0.5153315778838692\n",
      "training error at 15000 is: 0.04108047270680923\n",
      "test error at 15000 is: 0.27096229600450195\n",
      "current test loss is: 0.8420728826374098\n",
      "training loss at 20000 is: 0.3816186851681301\n",
      "training error at 20000 is: 0.024479459763646596\n",
      "test error at 20000 is: 0.26477208778840744\n",
      "current test loss is: 0.8128964929942177\n",
      "training loss at 25000 is: 0.2646484064369078\n",
      "training error at 25000 is: 0.017445132245357344\n",
      "test error at 25000 is: 0.2625211029825549\n",
      "current test loss is: 0.7954278717924432\n",
      "training loss at 30000 is: 0.19442269375721585\n",
      "training error at 30000 is: 0.0075970737197523916\n",
      "test error at 30000 is: 0.25886325267304444\n",
      "current test loss is: 0.787158372713145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 35000 is: 0.13835484378812227\n",
      "training error at 35000 is: 0.0036578503095104106\n",
      "test error at 35000 is: 0.25520540236353406\n",
      "current test loss is: 0.7817976925803636\n",
      "training loss at 40000 is: 0.09309387205137411\n",
      "training error at 40000 is: 0.0014068655036578502\n",
      "test error at 40000 is: 0.25323579065841306\n",
      "current test loss is: 0.7804174474873993\n",
      "training loss at 45000 is: 0.058096503093152264\n",
      "training error at 45000 is: 0.0008441193021947102\n",
      "test error at 45000 is: 0.24985931344963422\n",
      "current test loss is: 0.7793962426028587\n",
      "training loss at 50000 is: 0.03540163164738038\n",
      "training error at 50000 is: 0.0005627462014631402\n",
      "test error at 50000 is: 0.24845244794597637\n",
      "current test loss is: 0.7787325679013014\n",
      "training loss at 55000 is: 0.025308803800998477\n",
      "training error at 55000 is: 0.0005627462014631402\n",
      "test error at 55000 is: 0.25070343275182894\n",
      "current test loss is: 0.7789724712042697\n",
      "training loss at 60000 is: 0.014790169170845429\n",
      "training error at 60000 is: 0.0002813731007315701\n",
      "test error at 60000 is: 0.25323579065841306\n",
      "current test loss is: 0.7790304181285876\n",
      "training loss at 65000 is: 0.010470859556374024\n",
      "training error at 65000 is: 0.0002813731007315701\n",
      "test error at 65000 is: 0.2546426561620709\n",
      "current test loss is: 0.778886710442794\n",
      "training loss at 70000 is: 0.005967014781299612\n",
      "training error at 70000 is: 0.0\n",
      "test error at 70000 is: 0.2549240292628025\n",
      "current test loss is: 0.7790999686495456\n",
      "training loss at 75000 is: 0.003275847351929778\n",
      "training error at 75000 is: 0.0\n",
      "test error at 75000 is: 0.2537985368598762\n",
      "current test loss is: 0.7790448028326455\n",
      "training loss at 80000 is: 0.0025685048767345757\n",
      "training error at 80000 is: 0.0\n",
      "test error at 80000 is: 0.2543612830613393\n",
      "training error = 0.0, test error = 0.2543612830613393\n",
      "Test error of Combo is: 0.2543612830613393\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 0.9921168373329183\n",
      "training loss at 5000 is: 1.0513319141499302\n",
      "training error at 5000 is: 0.498030388294879\n",
      "test error at 5000 is: 0.4926842993809792\n",
      "current test loss is: 1.026073623991679\n",
      "training loss at 10000 is: 1.0329994118084858\n",
      "training error at 10000 is: 0.443725379853686\n",
      "test error at 10000 is: 0.41586944288126054\n",
      "current test loss is: 0.9366719164774099\n",
      "training loss at 15000 is: 1.0273306631254395\n",
      "training error at 15000 is: 0.4355655599324705\n",
      "test error at 15000 is: 0.4248733821046708\n",
      "current test loss is: 0.9413411757646518\n",
      "training loss at 20000 is: 1.0282591268673256\n",
      "training error at 20000 is: 0.5011254924029263\n",
      "test error at 20000 is: 0.5014068655036579\n",
      "current test loss is: 1.0102393227090314\n",
      "training loss at 25000 is: 1.0397583094266072\n",
      "training error at 25000 is: 0.5014068655036579\n",
      "test error at 25000 is: 0.5075970737197524\n",
      "current test loss is: 1.0746614712339\n",
      "training loss at 30000 is: 1.028826505980861\n",
      "training error at 30000 is: 0.47692740574001125\n",
      "test error at 30000 is: 0.45920090039392236\n",
      "current test loss is: 0.9445073435093644\n",
      "training loss at 35000 is: 1.0549958428643857\n",
      "training error at 35000 is: 0.4355655599324705\n",
      "test error at 35000 is: 0.4141812042768711\n",
      "current test loss is: 0.9392431594772335\n",
      "training loss at 40000 is: 1.026238989046789\n",
      "training error at 40000 is: 0.498030388294879\n",
      "test error at 40000 is: 0.4926842993809792\n",
      "current test loss is: 1.0120896456535007\n",
      "training loss at 45000 is: 1.0222852686485129\n",
      "training error at 45000 is: 0.4704558244231851\n",
      "test error at 45000 is: 0.46482836240855374\n",
      "current test loss is: 0.9366229473579154\n",
      "training loss at 50000 is: 1.0401765672283483\n",
      "training error at 50000 is: 0.4954980303882949\n",
      "test error at 50000 is: 0.49577940348902644\n",
      "current test loss is: 0.9508018658832785\n",
      "training loss at 55000 is: 1.0344645447438265\n",
      "training error at 55000 is: 0.496060776589758\n",
      "test error at 55000 is: 0.4946539110861002\n",
      "current test loss is: 0.9698771898262502\n",
      "training loss at 60000 is: 1.0152532120501487\n",
      "training error at 60000 is: 0.4316263365222285\n",
      "test error at 60000 is: 0.4248733821046708\n",
      "current test loss is: 0.9305592169715547\n",
      "training loss at 65000 is: 1.041353238345704\n",
      "training error at 65000 is: 0.46961170512099043\n",
      "test error at 65000 is: 0.4535734383792909\n",
      "training error = 0.46961170512099043, test error = 0.4535734383792909\n",
      "Test error of Word2Vec is: 0.4535734383792909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = readExamples('data/data_rt.train')\n",
    "train_new = []\n",
    "for example in train_set:\n",
    "    text = normalize_string(example[0])\n",
    "    label = example[1]\n",
    "    train_new.append((text, label))\n",
    "\n",
    "train_corpus = [example[0] for example in train_new]\n",
    "train_label = [example[1] for example in train_new]\n",
    "    \n",
    "test_set = readExamples('data/data_rt.test')\n",
    "test_new = []\n",
    "for example in test_set:\n",
    "    text = normalize_string(example[0])\n",
    "    label = example[1]\n",
    "    test_new.append((text, label))\n",
    "    \n",
    "test_corpus = [example[0] for example in test_new]\n",
    "test_label = [example[1] for example in test_new]\n",
    "    \n",
    "train_num = len(train_corpus)\n",
    "#mode_list = ['BOW', 'Bigram', 'Trigram', 'Combo', 'Word2Vec', 'Glove']\n",
    "mode_list = ['BOW', 'Bigram', 'Trigram', 'Combo', 'Word2Vec']\n",
    "combo_embed = extractFeatures(train_corpus + test_corpus, mode_list[1])\n",
    "train_embed = combo_embed[:train_num]\n",
    "test_embed = combo_embed[train_num:]\n",
    "    #train_data, val_data, train_l, val_l = train_test_split(train_embed, train_label, test_size = 0.1, random_state = 31)\n",
    "\n",
    "min_error = 1.0\n",
    "iters_list = [200000]\n",
    "learning_rate = [0.02, 0.1]\n",
    "reg_list = [0.0]\n",
    "best_w = None\n",
    "best_b = None\n",
    "best_combo = None\n",
    "for iters in iters_list:\n",
    "    for lr in learning_rate:\n",
    "        for reg in reg_list:\n",
    "            for mode in mode_list:\n",
    "                combo_embed = extractFeatures(train_corpus + test_corpus, mode)\n",
    "                train_embed = combo_embed[:train_num]\n",
    "                test_embed = combo_embed[train_num:]\n",
    "                w, b, testError = TestModel(iters, lr, reg, mode, train_embed, test_embed, train_label, test_label)\n",
    "                print('Test error of {} is: {}'.format(mode, testError))\n",
    "                    \n",
    "                #if valError < min_error:\n",
    "                    #best_w = w\n",
    "                    #best_b = b\n",
    "                    #best_combo = [iters, lr, reg]\n",
    "#print('Best hyper combo is: ')\n",
    "#print(best_combo)\n",
    "\n",
    "#testError = evaluatePredictor(test_embed, test_label, best_w, best_b)\n",
    "#print('Test error is: {}'.format(testError))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
