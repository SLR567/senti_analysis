{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1697e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from util import readExamples, evaluatePredictor\n",
    "from model import extractFeatures, learnPredictor, plot_loss\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add332b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0a31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b62471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(numIters, eta, reg, mode, train_data, test_data, train_label, test_label):\n",
    "    #train_set = readExamples('data/data_rt.train')\n",
    "    #train_new = []\n",
    "    #for example in train_set:\n",
    "        #text = normalize_string(example[0])\n",
    "        #label = example[1]\n",
    "        #train_new.append((text, label))\n",
    "\n",
    "    \n",
    "    #train_corpus = [example[0] for example in train_new]\n",
    "    \n",
    "    #train_label = [example[1] for example in train_new]\n",
    "   \n",
    "    #train_embed = extractFeatures(train_corpus, mode)\n",
    "    \n",
    "    #train_data, val_data, train_l, val_l = train_test_split(train_embed, train_label, test_size = 0.1, random_state = 31)\n",
    "    weight, bias, training_loss, test_error_list = learnPredictor(train_data, test_data, train_label, test_label, numIters=numIters, eta=eta, reg = reg)\n",
    "    \n",
    "    plot_loss(training_loss, 'train', mode, eta)\n",
    "    plot_loss(test_error_list, 'test', mode, eta)\n",
    "\n",
    "    trainError = evaluatePredictor(train_data, train_label, weight, bias)\n",
    "    testError = evaluatePredictor(test_data, test_label, weight, bias)\n",
    "    \n",
    "    print (\"training error = %s, test error = %s\" % (trainError, testError))\n",
    "    return weight, bias, testError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628609a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error at 0 is: 0.5014068655036579\n",
      "test error at 0 is: 0.4935284186831739\n",
      "current test loss is: 1.0000020233600262\n",
      "training loss at 5000 is: 0.9663863544076908\n",
      "training error at 5000 is: 0.19048958919527292\n",
      "test error at 5000 is: 0.28221722003376476\n",
      "current test loss is: 0.9578710095939273\n",
      "training loss at 10000 is: 0.8939231004747782\n",
      "training error at 10000 is: 0.18176702307259426\n",
      "test error at 10000 is: 0.2765897580191334\n",
      "current test loss is: 0.9145755229170989\n",
      "training loss at 15000 is: 0.8246045181068161\n",
      "training error at 15000 is: 0.18036015756893642\n",
      "test error at 15000 is: 0.2732132808103545\n",
      "current test loss is: 0.8738965102764824\n",
      "training loss at 20000 is: 0.7474506942686021\n",
      "training error at 20000 is: 0.17613956105796286\n",
      "test error at 20000 is: 0.2723691615081598\n",
      "current test loss is: 0.8335480120677965\n",
      "training loss at 25000 is: 0.6814327747347662\n",
      "training error at 25000 is: 0.16966797974113676\n",
      "test error at 25000 is: 0.2678671918964547\n",
      "current test loss is: 0.7985776981698688\n",
      "training loss at 30000 is: 0.6448436640644157\n",
      "training error at 30000 is: 0.16319639842431063\n",
      "test error at 30000 is: 0.26083286437816544\n",
      "current test loss is: 0.7714814269405441\n",
      "training loss at 35000 is: 0.5974825153389224\n",
      "training error at 35000 is: 0.15362971299943726\n",
      "test error at 35000 is: 0.2602701181767023\n",
      "current test loss is: 0.7498948119916444\n",
      "training loss at 40000 is: 0.5521202178279604\n",
      "training error at 40000 is: 0.14631401238041644\n",
      "test error at 40000 is: 0.263083849184018\n",
      "current test loss is: 0.7321228583795854\n",
      "training loss at 45000 is: 0.5346452254823887\n",
      "training error at 45000 is: 0.14153066966797975\n",
      "test error at 45000 is: 0.2583005064715813\n",
      "current test loss is: 0.7174024461772585\n",
      "training loss at 50000 is: 0.5029096685908201\n",
      "training error at 50000 is: 0.1297129994372538\n",
      "test error at 50000 is: 0.2622397298818233\n",
      "current test loss is: 0.7062021506853003\n",
      "training loss at 55000 is: 0.46978990012156707\n",
      "training error at 55000 is: 0.12464828362408553\n",
      "test error at 55000 is: 0.259144625773776\n",
      "current test loss is: 0.6960662507983534\n",
      "training loss at 60000 is: 0.45504771660096377\n",
      "training error at 60000 is: 0.12042768711311198\n",
      "test error at 60000 is: 0.2574563871693866\n",
      "current test loss is: 0.6879909715429274\n",
      "training loss at 65000 is: 0.43642443461936964\n",
      "training error at 65000 is: 0.11367473269555431\n",
      "test error at 65000 is: 0.2585818795723129\n",
      "current test loss is: 0.6807886995954232\n",
      "training loss at 70000 is: 0.4154338116036559\n",
      "training error at 70000 is: 0.10861001688238604\n",
      "test error at 70000 is: 0.2574563871693866\n",
      "current test loss is: 0.6744272789189665\n",
      "training loss at 75000 is: 0.40702946695752756\n",
      "training error at 75000 is: 0.10326392796848621\n",
      "test error at 75000 is: 0.25689364096792344\n",
      "current test loss is: 0.6695069797090394\n",
      "training loss at 80000 is: 0.3878935210549313\n",
      "training error at 80000 is: 0.10157568936409679\n",
      "test error at 80000 is: 0.25689364096792344\n",
      "current test loss is: 0.6646412588943938\n",
      "training loss at 85000 is: 0.36541326336416846\n",
      "training error at 85000 is: 0.09791783905458638\n",
      "test error at 85000 is: 0.25717501406865506\n",
      "current test loss is: 0.6605788567643048\n",
      "training loss at 90000 is: 0.36277104821636624\n",
      "training error at 90000 is: 0.09425998874507598\n",
      "test error at 90000 is: 0.259144625773776\n",
      "current test loss is: 0.6568766486876355\n",
      "training loss at 95000 is: 0.35147047303406465\n",
      "training error at 95000 is: 0.09454136184580754\n",
      "test error at 95000 is: 0.25801913337084975\n",
      "current test loss is: 0.6531542828194852\n",
      "training loss at 100000 is: 0.32817230761657723\n",
      "training error at 100000 is: 0.09285312324141812\n",
      "test error at 100000 is: 0.259144625773776\n",
      "current test loss is: 0.6503708958368789\n",
      "training loss at 105000 is: 0.3199229786378809\n",
      "training error at 105000 is: 0.088351153629713\n",
      "test error at 105000 is: 0.25886325267304444\n",
      "current test loss is: 0.648098382989547\n",
      "training loss at 110000 is: 0.31937226545454495\n",
      "training error at 110000 is: 0.08610016882386044\n",
      "test error at 110000 is: 0.2583005064715813\n",
      "training error = 0.08610016882386044, test error = 0.2583005064715813\n",
      "Test error of BOW is: 0.2583005064715813\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9850358954985501\n",
      "training error at 5000 is: 0.10213843556555993\n",
      "test error at 5000 is: 0.4192459200900394\n",
      "current test loss is: 0.9984226509104794\n",
      "training loss at 10000 is: 0.954559656108316\n",
      "training error at 10000 is: 0.032357906584130555\n",
      "test error at 10000 is: 0.4108047270680923\n",
      "current test loss is: 0.9967181439608769\n",
      "training loss at 15000 is: 0.9240081453164303\n",
      "training error at 15000 is: 0.013224535734383792\n",
      "test error at 15000 is: 0.4088351153629713\n",
      "current test loss is: 0.9949871573310313\n",
      "training loss at 20000 is: 0.8955802181985569\n",
      "training error at 20000 is: 0.0075970737197523916\n",
      "test error at 20000 is: 0.4093978615644344\n",
      "current test loss is: 0.9934725822760374\n",
      "training loss at 25000 is: 0.8649173957271109\n",
      "training error at 25000 is: 0.005064715813168261\n",
      "test error at 25000 is: 0.4105233539673607\n",
      "current test loss is: 0.9917715944356031\n",
      "training loss at 30000 is: 0.8359125371645796\n",
      "training error at 30000 is: 0.0030951041080472708\n",
      "test error at 30000 is: 0.4060213843556556\n",
      "current test loss is: 0.9901173123858175\n",
      "training loss at 35000 is: 0.8055855195731163\n",
      "training error at 35000 is: 0.0030951041080472708\n",
      "test error at 35000 is: 0.40461451885199773\n",
      "current test loss is: 0.988634879327628\n",
      "training loss at 40000 is: 0.7739859535268759\n",
      "training error at 40000 is: 0.0028137310073157004\n",
      "test error at 40000 is: 0.40433314575126617\n",
      "current test loss is: 0.9868121703093184\n",
      "training loss at 45000 is: 0.7427444761656483\n",
      "training error at 45000 is: 0.0025323579065841305\n",
      "test error at 45000 is: 0.4060213843556556\n",
      "current test loss is: 0.9850855946342404\n",
      "training loss at 50000 is: 0.7129125845420148\n",
      "training error at 50000 is: 0.0025323579065841305\n",
      "test error at 50000 is: 0.4060213843556556\n",
      "current test loss is: 0.9833734771895882\n",
      "training loss at 55000 is: 0.683009531650301\n",
      "training error at 55000 is: 0.0019696117051209903\n",
      "test error at 55000 is: 0.40770962296004504\n",
      "current test loss is: 0.9818155527127612\n",
      "training loss at 60000 is: 0.6535299697921231\n",
      "training error at 60000 is: 0.0019696117051209903\n",
      "test error at 60000 is: 0.4079909960607766\n",
      "current test loss is: 0.9800586671496754\n",
      "training loss at 65000 is: 0.6249129079934947\n",
      "training error at 65000 is: 0.0019696117051209903\n",
      "test error at 65000 is: 0.40658413055711873\n",
      "current test loss is: 0.9784477276956738\n",
      "training loss at 70000 is: 0.5963732202360245\n",
      "training error at 70000 is: 0.0016882386043894203\n",
      "test error at 70000 is: 0.4060213843556556\n",
      "training error = 0.0016882386043894203, test error = 0.4060213843556556\n",
      "Test error of Bigram is: 0.4060213843556556\n",
      "training error at 0 is: 0.49774901519414744\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9865717832768925\n",
      "training error at 5000 is: 0.12296004501969612\n",
      "test error at 5000 is: 0.4825548677546427\n",
      "current test loss is: 0.9998745235444543\n",
      "training loss at 10000 is: 0.9592981121038955\n",
      "training error at 10000 is: 0.03460889138998312\n",
      "test error at 10000 is: 0.48227349465391106\n",
      "current test loss is: 0.9997918503159201\n",
      "training loss at 15000 is: 0.9311993252637001\n",
      "training error at 15000 is: 0.014631401238041642\n",
      "test error at 15000 is: 0.48086662915025324\n",
      "current test loss is: 0.9996931728989673\n",
      "training loss at 20000 is: 0.9028134803326808\n",
      "training error at 20000 is: 0.010410804727068092\n",
      "test error at 20000 is: 0.4805852560495217\n",
      "current test loss is: 0.9995540385854081\n",
      "training loss at 25000 is: 0.8755482571636383\n",
      "training error at 25000 is: 0.009285312324141813\n",
      "test error at 25000 is: 0.48086662915025324\n",
      "current test loss is: 0.9993978143096093\n",
      "training loss at 30000 is: 0.8483270017465273\n",
      "training error at 30000 is: 0.009285312324141813\n",
      "test error at 30000 is: 0.4805852560495217\n",
      "current test loss is: 0.9993018555287526\n",
      "training loss at 35000 is: 0.8202309771112128\n",
      "training error at 35000 is: 0.009285312324141813\n",
      "test error at 35000 is: 0.4811480022509848\n",
      "current test loss is: 0.9991900097759536\n",
      "training loss at 40000 is: 0.7919438956404682\n",
      "training error at 40000 is: 0.009285312324141813\n",
      "test error at 40000 is: 0.4805852560495217\n",
      "current test loss is: 0.9990850680976432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 45000 is: 0.7663786398006479\n",
      "training error at 45000 is: 0.009285312324141813\n",
      "test error at 45000 is: 0.48086662915025324\n",
      "current test loss is: 0.998956410393301\n",
      "training loss at 50000 is: 0.7362376408369309\n",
      "training error at 50000 is: 0.009285312324141813\n",
      "test error at 50000 is: 0.48086662915025324\n",
      "current test loss is: 0.9988323632354853\n",
      "training loss at 55000 is: 0.7112268757591751\n",
      "training error at 55000 is: 0.009285312324141813\n",
      "test error at 55000 is: 0.4805852560495217\n",
      "current test loss is: 0.9987362377963689\n",
      "training loss at 60000 is: 0.6824759191902704\n",
      "training error at 60000 is: 0.009285312324141813\n",
      "test error at 60000 is: 0.48086662915025324\n",
      "current test loss is: 0.9986140729579082\n",
      "training loss at 65000 is: 0.652930139064929\n",
      "training error at 65000 is: 0.009285312324141813\n",
      "test error at 65000 is: 0.48086662915025324\n",
      "current test loss is: 0.998517030480121\n",
      "training loss at 70000 is: 0.6286983546000426\n",
      "training error at 70000 is: 0.009285312324141813\n",
      "test error at 70000 is: 0.4803038829487901\n",
      "current test loss is: 0.9984003449269074\n",
      "training loss at 75000 is: 0.5983742306130041\n",
      "training error at 75000 is: 0.009285312324141813\n",
      "test error at 75000 is: 0.48086662915025324\n",
      "current test loss is: 0.9982715694507966\n",
      "training loss at 80000 is: 0.573878188539388\n",
      "training error at 80000 is: 0.009285312324141813\n",
      "test error at 80000 is: 0.4800225098480585\n",
      "current test loss is: 0.9981371731545444\n",
      "training loss at 85000 is: 0.5453517042743979\n",
      "training error at 85000 is: 0.009285312324141813\n",
      "test error at 85000 is: 0.4800225098480585\n",
      "current test loss is: 0.9980405784145239\n",
      "training loss at 90000 is: 0.515938443116087\n",
      "training error at 90000 is: 0.009285312324141813\n",
      "test error at 90000 is: 0.48086662915025324\n",
      "current test loss is: 0.9979222723770508\n",
      "training loss at 95000 is: 0.488485726014746\n",
      "training error at 95000 is: 0.009285312324141813\n",
      "test error at 95000 is: 0.4803038829487901\n",
      "current test loss is: 0.9977904783248625\n",
      "training loss at 100000 is: 0.4629190463262811\n",
      "training error at 100000 is: 0.009285312324141813\n",
      "test error at 100000 is: 0.4805852560495217\n",
      "current test loss is: 0.9976735966916712\n",
      "training loss at 105000 is: 0.43539880255272684\n",
      "training error at 105000 is: 0.009285312324141813\n",
      "test error at 105000 is: 0.4805852560495217\n",
      "current test loss is: 0.9975626500156883\n",
      "training loss at 110000 is: 0.4067697954447572\n",
      "training error at 110000 is: 0.009285312324141813\n",
      "test error at 110000 is: 0.4805852560495217\n",
      "current test loss is: 0.9974308698533154\n",
      "training loss at 115000 is: 0.37865176752722474\n",
      "training error at 115000 is: 0.009285312324141813\n",
      "test error at 115000 is: 0.4805852560495217\n",
      "training error = 0.009285312324141813, test error = 0.4805852560495217\n",
      "Test error of Trigram is: 0.4805852560495217\n",
      "training error at 0 is: 0.49887450759707375\n",
      "test error at 0 is: 0.49296567248171075\n",
      "current test loss is: 0.9999995059826589\n",
      "training loss at 5000 is: 0.9804376051349815\n",
      "training error at 5000 is: 0.09735509285312324\n",
      "test error at 5000 is: 0.28418683173888576\n",
      "current test loss is: 0.9893631027435928\n",
      "training loss at 10000 is: 0.9402101845693244\n",
      "training error at 10000 is: 0.06527855936972425\n",
      "test error at 10000 is: 0.2746201463140124\n",
      "current test loss is: 0.9775812910363784\n",
      "training loss at 15000 is: 0.899917484274957\n",
      "training error at 15000 is: 0.04952166572875633\n",
      "test error at 15000 is: 0.2726505346088914\n",
      "current test loss is: 0.9661048263937465\n",
      "training loss at 20000 is: 0.8606642941775877\n",
      "training error at 20000 is: 0.04445694991558807\n",
      "test error at 20000 is: 0.26927405740011257\n",
      "current test loss is: 0.954952955174034\n",
      "training loss at 25000 is: 0.8202418075015112\n",
      "training error at 25000 is: 0.03967360720315138\n",
      "test error at 25000 is: 0.26702307259426\n",
      "current test loss is: 0.9434682179869595\n",
      "training loss at 30000 is: 0.7847957012806073\n",
      "training error at 30000 is: 0.03432751828925155\n",
      "test error at 30000 is: 0.26364659538548113\n",
      "current test loss is: 0.9325868240150835\n",
      "training loss at 35000 is: 0.7454109041196699\n",
      "training error at 35000 is: 0.03404614518851998\n",
      "test error at 35000 is: 0.2664603263927969\n",
      "current test loss is: 0.9213152497642438\n",
      "training loss at 40000 is: 0.7032161478298071\n",
      "training error at 40000 is: 0.032076533483398985\n",
      "test error at 40000 is: 0.2639279684862127\n",
      "current test loss is: 0.9097305027740847\n",
      "training loss at 45000 is: 0.6646934338719388\n",
      "training error at 45000 is: 0.031795160382667415\n",
      "test error at 45000 is: 0.2658975801913337\n",
      "current test loss is: 0.8988135276182184\n",
      "training loss at 50000 is: 0.6252949546548449\n",
      "training error at 50000 is: 0.029544175576814855\n",
      "test error at 50000 is: 0.2664603263927969\n",
      "current test loss is: 0.887882660090283\n",
      "training loss at 55000 is: 0.5902719967698383\n",
      "training error at 55000 is: 0.027574563871693866\n",
      "test error at 55000 is: 0.2639279684862127\n",
      "current test loss is: 0.8774666896282115\n",
      "training loss at 60000 is: 0.5527421635420593\n",
      "training error at 60000 is: 0.025042205965109737\n",
      "test error at 60000 is: 0.26674169949352844\n",
      "training error = 0.025042205965109737, test error = 0.26674169949352844\n",
      "Test error of Combo is: 0.26674169949352844\n",
      "training error at 0 is: 0.5016882386043894\n",
      "test error at 0 is: 0.5073157006190209\n",
      "current test loss is: 1.0019038874275847\n",
      "training loss at 5000 is: 1.003443912795198\n",
      "training error at 5000 is: 0.44400675295441755\n",
      "test error at 5000 is: 0.4220596510973551\n",
      "current test loss is: 0.9577976983472349\n",
      "training loss at 10000 is: 0.9934832722063278\n",
      "training error at 10000 is: 0.4333145751266179\n",
      "test error at 10000 is: 0.4257175014068655\n",
      "current test loss is: 0.9457255976329891\n",
      "training loss at 15000 is: 0.9834664650467304\n",
      "training error at 15000 is: 0.43669105233539673\n",
      "test error at 15000 is: 0.42121553179516036\n",
      "current test loss is: 0.9363125950898049\n",
      "training loss at 20000 is: 0.9711550137442826\n",
      "training error at 20000 is: 0.4966235227912212\n",
      "test error at 20000 is: 0.4912774338773213\n",
      "current test loss is: 0.9538094623548391\n",
      "training loss at 25000 is: 0.9741847776121669\n",
      "training error at 25000 is: 0.5005627462014631\n",
      "test error at 25000 is: 0.49887450759707375\n",
      "current test loss is: 0.9735474515085448\n",
      "training loss at 30000 is: 0.9724039218532531\n",
      "training error at 30000 is: 0.44259988745075973\n",
      "test error at 30000 is: 0.42177827799662354\n",
      "current test loss is: 0.9368057409057744\n",
      "training loss at 35000 is: 0.9820609341134621\n",
      "training error at 35000 is: 0.4991558806978053\n",
      "test error at 35000 is: 0.4932470455824423\n",
      "current test loss is: 0.9628558441368686\n",
      "training loss at 40000 is: 0.9766279118503233\n",
      "training error at 40000 is: 0.45610579628587505\n",
      "test error at 40000 is: 0.4473832301631964\n",
      "current test loss is: 0.9411248797151845\n",
      "training loss at 45000 is: 0.9666199207860405\n",
      "training error at 45000 is: 0.48283624085537424\n",
      "test error at 45000 is: 0.4637028700056275\n",
      "training error = 0.48283624085537424, test error = 0.4637028700056275\n",
      "Test error of Word2Vec is: 0.4637028700056275\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0000156534694111\n",
      "training loss at 5000 is: 0.817042845818305\n",
      "training error at 5000 is: 0.19499155880697805\n",
      "test error at 5000 is: 0.2858750703432752\n",
      "current test loss is: 0.7918780882526224\n",
      "training loss at 10000 is: 0.5804363357964274\n",
      "training error at 10000 is: 0.15447383230163197\n",
      "test error at 10000 is: 0.2644907146876759\n",
      "current test loss is: 0.7081500139040748\n",
      "training loss at 15000 is: 0.4549758600380156\n",
      "training error at 15000 is: 0.11451885199774901\n",
      "test error at 15000 is: 0.25604952166572875\n",
      "current test loss is: 0.6678072004632781\n",
      "training loss at 20000 is: 0.370249123309143\n",
      "training error at 20000 is: 0.09819921215531795\n",
      "test error at 20000 is: 0.2594259988745076\n",
      "current test loss is: 0.6480966751482405\n",
      "training loss at 25000 is: 0.30855551813239007\n",
      "training error at 25000 is: 0.08666291502532358\n",
      "test error at 25000 is: 0.2577377602701182\n",
      "current test loss is: 0.6381798415484337\n",
      "training loss at 30000 is: 0.26596021565154654\n",
      "training error at 30000 is: 0.07118739448508722\n",
      "test error at 30000 is: 0.25689364096792344\n",
      "current test loss is: 0.6312869471767106\n",
      "training loss at 35000 is: 0.24186868727315836\n",
      "training error at 35000 is: 0.06471581316826111\n",
      "test error at 35000 is: 0.25717501406865506\n",
      "current test loss is: 0.6267100665304366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 40000 is: 0.20581212212055117\n",
      "training error at 40000 is: 0.056555993247045584\n",
      "test error at 40000 is: 0.26195835678109175\n",
      "current test loss is: 0.6222999596493537\n",
      "training loss at 45000 is: 0.18804707166617007\n",
      "training error at 45000 is: 0.050928531232414184\n",
      "test error at 45000 is: 0.26167698368036013\n",
      "training error = 0.050928531232414184, test error = 0.26167698368036013\n",
      "Test error of BOW is: 0.26167698368036013\n",
      "training error at 0 is: 0.49774901519414744\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9277262145299233\n",
      "training error at 5000 is: 0.10354530106921778\n",
      "test error at 5000 is: 0.41840180078784467\n",
      "current test loss is: 0.9917793887532202\n",
      "training loss at 10000 is: 0.7746720753218456\n",
      "training error at 10000 is: 0.030951041080472707\n",
      "test error at 10000 is: 0.415588069780529\n",
      "current test loss is: 0.9839351008682391\n",
      "training loss at 15000 is: 0.6320433243043775\n",
      "training error at 15000 is: 0.009285312324141813\n",
      "test error at 15000 is: 0.4105233539673607\n",
      "current test loss is: 0.9763051702070963\n",
      "training loss at 20000 is: 0.48029022001675914\n",
      "training error at 20000 is: 0.005908835115362971\n",
      "test error at 20000 is: 0.4113674732695554\n",
      "current test loss is: 0.9686061583886542\n",
      "training loss at 25000 is: 0.3541611825895873\n",
      "training error at 25000 is: 0.0028137310073157004\n",
      "test error at 25000 is: 0.4088351153629713\n",
      "current test loss is: 0.9630233111065206\n",
      "training loss at 30000 is: 0.24061619976974857\n",
      "training error at 30000 is: 0.0019696117051209903\n",
      "test error at 30000 is: 0.4108047270680923\n",
      "current test loss is: 0.959114222678808\n",
      "training loss at 35000 is: 0.1595362277671637\n",
      "training error at 35000 is: 0.0016882386043894203\n",
      "test error at 35000 is: 0.41108610016882385\n",
      "current test loss is: 0.9563846624630341\n",
      "training loss at 40000 is: 0.1009533110127113\n",
      "training error at 40000 is: 0.0016882386043894203\n",
      "test error at 40000 is: 0.40911648846370285\n",
      "current test loss is: 0.9544104819182256\n",
      "training loss at 45000 is: 0.06326761420060115\n",
      "training error at 45000 is: 0.0011254924029262803\n",
      "test error at 45000 is: 0.40827236916150816\n",
      "current test loss is: 0.9529768386600609\n",
      "training loss at 50000 is: 0.03649621243669708\n",
      "training error at 50000 is: 0.0011254924029262803\n",
      "test error at 50000 is: 0.4054586381541925\n",
      "current test loss is: 0.952454187396149\n",
      "training loss at 55000 is: 0.022856806962405836\n",
      "training error at 55000 is: 0.0011254924029262803\n",
      "test error at 55000 is: 0.40658413055711873\n",
      "current test loss is: 0.9520597051826903\n",
      "training loss at 60000 is: 0.013898876442937478\n",
      "training error at 60000 is: 0.0011254924029262803\n",
      "test error at 60000 is: 0.40658413055711873\n",
      "current test loss is: 0.95182720041829\n",
      "training loss at 65000 is: 0.007927426922622466\n",
      "training error at 65000 is: 0.0011254924029262803\n",
      "test error at 65000 is: 0.40574001125492404\n",
      "current test loss is: 0.951580044331723\n",
      "training loss at 70000 is: 0.005309921561369709\n",
      "training error at 70000 is: 0.0011254924029262803\n",
      "test error at 70000 is: 0.4054586381541925\n",
      "current test loss is: 0.9514279640465629\n",
      "training loss at 75000 is: 0.0052135816116926125\n",
      "training error at 75000 is: 0.0011254924029262803\n",
      "test error at 75000 is: 0.4051772650534609\n",
      "current test loss is: 0.9514735565846351\n",
      "training loss at 80000 is: 0.0044507388718621485\n",
      "training error at 80000 is: 0.0011254924029262803\n",
      "test error at 80000 is: 0.4054586381541925\n",
      "current test loss is: 0.9514111280878317\n",
      "training loss at 85000 is: 0.004392432697239354\n",
      "training error at 85000 is: 0.0011254924029262803\n",
      "test error at 85000 is: 0.4054586381541925\n",
      "current test loss is: 0.9514057174640034\n",
      "training loss at 90000 is: 0.0028770218199710667\n",
      "training error at 90000 is: 0.0011254924029262803\n",
      "test error at 90000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513926089512769\n",
      "training loss at 95000 is: 0.0030009823980718317\n",
      "training error at 95000 is: 0.0011254924029262803\n",
      "test error at 95000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 100000 is: 0.0034018601730676067\n",
      "training error at 100000 is: 0.0011254924029262803\n",
      "test error at 100000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 105000 is: 0.0032\n",
      "training error at 105000 is: 0.0011254924029262803\n",
      "test error at 105000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 110000 is: 0.0044\n",
      "training error at 110000 is: 0.0011254924029262803\n",
      "test error at 110000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 115000 is: 0.0026\n",
      "training error at 115000 is: 0.0011254924029262803\n",
      "test error at 115000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 120000 is: 0.0022\n",
      "training error at 120000 is: 0.0011254924029262803\n",
      "test error at 120000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 125000 is: 0.0038\n",
      "training error at 125000 is: 0.0011254924029262803\n",
      "test error at 125000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 130000 is: 0.003\n",
      "training error at 130000 is: 0.0011254924029262803\n",
      "test error at 130000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 135000 is: 0.003\n",
      "training error at 135000 is: 0.0011254924029262803\n",
      "test error at 135000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 140000 is: 0.0022\n",
      "training error at 140000 is: 0.0011254924029262803\n",
      "test error at 140000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 145000 is: 0.0036\n",
      "training error at 145000 is: 0.0011254924029262803\n",
      "test error at 145000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 150000 is: 0.0038\n",
      "training error at 150000 is: 0.0011254924029262803\n",
      "test error at 150000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 155000 is: 0.004\n",
      "training error at 155000 is: 0.0011254924029262803\n",
      "test error at 155000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 160000 is: 0.0022\n",
      "training error at 160000 is: 0.0011254924029262803\n",
      "test error at 160000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 165000 is: 0.0034\n",
      "training error at 165000 is: 0.0011254924029262803\n",
      "test error at 165000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 170000 is: 0.0024\n",
      "training error at 170000 is: 0.0011254924029262803\n",
      "test error at 170000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 175000 is: 0.0032\n",
      "training error at 175000 is: 0.0011254924029262803\n",
      "test error at 175000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 180000 is: 0.0032\n",
      "training error at 180000 is: 0.0011254924029262803\n",
      "test error at 180000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 185000 is: 0.0028\n",
      "training error at 185000 is: 0.0011254924029262803\n",
      "test error at 185000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 190000 is: 0.0036\n",
      "training error at 190000 is: 0.0011254924029262803\n",
      "test error at 190000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training loss at 195000 is: 0.0024\n",
      "training error at 195000 is: 0.0011254924029262803\n",
      "test error at 195000 is: 0.4051772650534609\n",
      "current test loss is: 0.9513964456565389\n",
      "training error = 0.0011254924029262803, test error = 0.4051772650534609\n",
      "Test error of Bigram is: 0.4051772650534609\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.9300519724977672\n",
      "training error at 5000 is: 0.12549240292628025\n",
      "test error at 5000 is: 0.4839617332583005\n",
      "current test loss is: 0.9993410890514124\n",
      "training loss at 10000 is: 0.7920208589736255\n",
      "training error at 10000 is: 0.037703995498030385\n",
      "test error at 10000 is: 0.48171074845244793\n",
      "current test loss is: 0.9987468478509572\n",
      "training loss at 15000 is: 0.6555843067166899\n",
      "training error at 15000 is: 0.018007878446820485\n",
      "test error at 15000 is: 0.4811480022509848\n",
      "current test loss is: 0.9982670766488552\n",
      "training loss at 20000 is: 0.5157291766014975\n",
      "training error at 20000 is: 0.011254924029262802\n",
      "test error at 20000 is: 0.48086662915025324\n",
      "current test loss is: 0.997771143185985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 25000 is: 0.3863421546372628\n",
      "training error at 25000 is: 0.009566685424873381\n",
      "test error at 25000 is: 0.48086662915025324\n",
      "current test loss is: 0.9973170739221988\n",
      "training loss at 30000 is: 0.27554057967293927\n",
      "training error at 30000 is: 0.009285312324141813\n",
      "test error at 30000 is: 0.48086662915025324\n",
      "current test loss is: 0.9969894209399903\n",
      "training loss at 35000 is: 0.18631656902657467\n",
      "training error at 35000 is: 0.009285312324141813\n",
      "test error at 35000 is: 0.48086662915025324\n",
      "current test loss is: 0.996612459056943\n",
      "training loss at 40000 is: 0.12386161753878218\n",
      "training error at 40000 is: 0.009285312324141813\n",
      "test error at 40000 is: 0.4803038829487901\n",
      "current test loss is: 0.9964584640508767\n",
      "training loss at 45000 is: 0.08202174016796199\n",
      "training error at 45000 is: 0.009285312324141813\n",
      "test error at 45000 is: 0.4805852560495217\n",
      "current test loss is: 0.9962593554439111\n",
      "training loss at 50000 is: 0.05444467675868169\n",
      "training error at 50000 is: 0.009285312324141813\n",
      "test error at 50000 is: 0.4805852560495217\n",
      "current test loss is: 0.996052018944168\n",
      "training loss at 55000 is: 0.03723632652505394\n",
      "training error at 55000 is: 0.009285312324141813\n",
      "test error at 55000 is: 0.4803038829487901\n",
      "current test loss is: 0.9960130161471179\n",
      "training loss at 60000 is: 0.028733893240646808\n",
      "training error at 60000 is: 0.009285312324141813\n",
      "test error at 60000 is: 0.4800225098480585\n",
      "current test loss is: 0.9960052803714771\n",
      "training loss at 65000 is: 0.022498418815435527\n",
      "training error at 65000 is: 0.009285312324141813\n",
      "test error at 65000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911933843856\n",
      "training loss at 70000 is: 0.022129090110575716\n",
      "training error at 70000 is: 0.009285312324141813\n",
      "test error at 70000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 75000 is: 0.02336128079505764\n",
      "training error at 75000 is: 0.009285312324141813\n",
      "test error at 75000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 80000 is: 0.02188\n",
      "training error at 80000 is: 0.009285312324141813\n",
      "test error at 80000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 85000 is: 0.024446086526081556\n",
      "training error at 85000 is: 0.009285312324141813\n",
      "test error at 85000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 90000 is: 0.023819999999999997\n",
      "training error at 90000 is: 0.009285312324141813\n",
      "test error at 90000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 95000 is: 0.0216\n",
      "training error at 95000 is: 0.009285312324141813\n",
      "test error at 95000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959911765162646\n",
      "training loss at 100000 is: 0.02161214727878604\n",
      "training error at 100000 is: 0.009285312324141813\n",
      "test error at 100000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 105000 is: 0.026\n",
      "training error at 105000 is: 0.009285312324141813\n",
      "test error at 105000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 110000 is: 0.0226\n",
      "training error at 110000 is: 0.009285312324141813\n",
      "test error at 110000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 115000 is: 0.0224\n",
      "training error at 115000 is: 0.009285312324141813\n",
      "test error at 115000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 120000 is: 0.0194\n",
      "training error at 120000 is: 0.009285312324141813\n",
      "test error at 120000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 125000 is: 0.0212\n",
      "training error at 125000 is: 0.009285312324141813\n",
      "test error at 125000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 130000 is: 0.0214\n",
      "training error at 130000 is: 0.009285312324141813\n",
      "test error at 130000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 135000 is: 0.0196\n",
      "training error at 135000 is: 0.009285312324141813\n",
      "test error at 135000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 140000 is: 0.025\n",
      "training error at 140000 is: 0.009285312324141813\n",
      "test error at 140000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 145000 is: 0.0224\n",
      "training error at 145000 is: 0.009285312324141813\n",
      "test error at 145000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 150000 is: 0.0208\n",
      "training error at 150000 is: 0.009285312324141813\n",
      "test error at 150000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 155000 is: 0.0232\n",
      "training error at 155000 is: 0.009285312324141813\n",
      "test error at 155000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 160000 is: 0.0214\n",
      "training error at 160000 is: 0.009285312324141813\n",
      "test error at 160000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 165000 is: 0.0218\n",
      "training error at 165000 is: 0.009285312324141813\n",
      "test error at 165000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 170000 is: 0.022\n",
      "training error at 170000 is: 0.009285312324141813\n",
      "test error at 170000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 175000 is: 0.0282\n",
      "training error at 175000 is: 0.009285312324141813\n",
      "test error at 175000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 180000 is: 0.023\n",
      "training error at 180000 is: 0.009285312324141813\n",
      "test error at 180000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 185000 is: 0.0204\n",
      "training error at 185000 is: 0.009285312324141813\n",
      "test error at 185000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 190000 is: 0.022\n",
      "training error at 190000 is: 0.009285312324141813\n",
      "test error at 190000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training loss at 195000 is: 0.0228\n",
      "training error at 195000 is: 0.009285312324141813\n",
      "test error at 195000 is: 0.4800225098480585\n",
      "current test loss is: 0.9959883334540399\n",
      "training error = 0.009285312324141813, test error = 0.4800225098480585\n",
      "Test error of Trigram is: 0.4800225098480585\n",
      "training error at 0 is: 0.4845244794597636\n",
      "test error at 0 is: 0.4786156443444007\n",
      "current test loss is: 0.9999531412413165\n",
      "training loss at 5000 is: 0.8992251257492649\n",
      "training error at 5000 is: 0.10129431626336523\n",
      "test error at 5000 is: 0.2864378165447383\n",
      "current test loss is: 0.9426886798804942\n",
      "training loss at 10000 is: 0.7077264391234315\n",
      "training error at 10000 is: 0.056555993247045584\n",
      "test error at 10000 is: 0.2732132808103545\n",
      "current test loss is: 0.8892080741658493\n",
      "training loss at 15000 is: 0.5298517888924725\n",
      "training error at 15000 is: 0.038266741699493526\n",
      "test error at 15000 is: 0.2726505346088914\n",
      "current test loss is: 0.8455286137788244\n",
      "training loss at 20000 is: 0.3806599028590886\n",
      "training error at 20000 is: 0.021384355655599326\n",
      "test error at 20000 is: 0.2639279684862127\n",
      "current test loss is: 0.8149317086775401\n",
      "training loss at 25000 is: 0.26981101066745766\n",
      "training error at 25000 is: 0.012661789532920653\n",
      "test error at 25000 is: 0.259144625773776\n",
      "current test loss is: 0.7971322964936978\n",
      "training loss at 30000 is: 0.18984870002305812\n",
      "training error at 30000 is: 0.007315700619020821\n",
      "test error at 30000 is: 0.2566122678671919\n",
      "current test loss is: 0.7862689453776274\n",
      "training loss at 35000 is: 0.12510238530870835\n",
      "training error at 35000 is: 0.004501969611705121\n",
      "test error at 35000 is: 0.2518289251547552\n",
      "current test loss is: 0.7808109813755298\n",
      "training loss at 40000 is: 0.0864311924879944\n",
      "training error at 40000 is: 0.0025323579065841305\n",
      "test error at 40000 is: 0.24957794034890265\n",
      "current test loss is: 0.779166418792033\n",
      "training loss at 45000 is: 0.056757907038578005\n",
      "training error at 45000 is: 0.0005627462014631402\n",
      "test error at 45000 is: 0.24873382104670794\n",
      "current test loss is: 0.7788654201661017\n",
      "training loss at 50000 is: 0.040053627448403475\n",
      "training error at 50000 is: 0.0002813731007315701\n",
      "test error at 50000 is: 0.2504220596510974\n",
      "current test loss is: 0.7789408051044681\n",
      "training loss at 55000 is: 0.025378113214471733\n",
      "training error at 55000 is: 0.0002813731007315701\n",
      "test error at 55000 is: 0.24985931344963422\n",
      "current test loss is: 0.7791509026083486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 60000 is: 0.012119643220588462\n",
      "training error at 60000 is: 0.0002813731007315701\n",
      "test error at 60000 is: 0.24957794034890265\n",
      "current test loss is: 0.779074869532214\n",
      "training loss at 65000 is: 0.008648979096324215\n",
      "training error at 65000 is: 0.0002813731007315701\n",
      "test error at 65000 is: 0.24929656724817106\n",
      "current test loss is: 0.7791981731026153\n",
      "training loss at 70000 is: 0.005374691653744922\n",
      "training error at 70000 is: 0.0\n",
      "test error at 70000 is: 0.2518289251547552\n",
      "current test loss is: 0.7791421268917766\n",
      "training loss at 75000 is: 0.004419438475118238\n",
      "training error at 75000 is: 0.0\n",
      "test error at 75000 is: 0.25239167135621837\n",
      "training error = 0.0, test error = 0.25239167135621837\n",
      "Test error of Combo is: 0.25239167135621837\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 0.9957639016367903\n",
      "training loss at 5000 is: 1.0446304499803452\n",
      "training error at 5000 is: 0.5016882386043894\n",
      "test error at 5000 is: 0.5073157006190209\n",
      "current test loss is: 1.1955605351599443\n",
      "training loss at 10000 is: 1.032353872586014\n",
      "training error at 10000 is: 0.5002813731007316\n",
      "test error at 10000 is: 0.5070343275182893\n",
      "current test loss is: 1.1658219910775227\n",
      "training loss at 15000 is: 1.0341753365262663\n",
      "training error at 15000 is: 0.498030388294879\n",
      "test error at 15000 is: 0.49296567248171075\n",
      "current test loss is: 1.0309730173261247\n",
      "training loss at 20000 is: 1.0359022795845148\n",
      "training error at 20000 is: 0.4662352279122116\n",
      "test error at 20000 is: 0.44794597636465955\n",
      "current test loss is: 0.9384336996446279\n",
      "training loss at 25000 is: 1.0320765265083374\n",
      "training error at 25000 is: 0.4946539110861002\n",
      "test error at 25000 is: 0.4879009566685425\n",
      "current test loss is: 0.9897085831044404\n",
      "training loss at 30000 is: 1.053020853269231\n",
      "training error at 30000 is: 0.4293753517163759\n",
      "test error at 30000 is: 0.42318514350028136\n",
      "current test loss is: 0.9593552590785345\n",
      "training loss at 35000 is: 1.029141825143391\n",
      "training error at 35000 is: 0.46961170512099043\n",
      "test error at 35000 is: 0.4622960045019696\n",
      "current test loss is: 0.9394927058608264\n",
      "training loss at 40000 is: 1.035572955724219\n",
      "training error at 40000 is: 0.498030388294879\n",
      "test error at 40000 is: 0.4926842993809792\n",
      "current test loss is: 1.2789736871168875\n",
      "training loss at 45000 is: 1.0320506132381606\n",
      "training error at 45000 is: 0.498030388294879\n",
      "test error at 45000 is: 0.4926842993809792\n",
      "current test loss is: 0.9672015715686645\n",
      "training loss at 50000 is: 1.0236874009673051\n",
      "training error at 50000 is: 0.5008441193021947\n",
      "test error at 50000 is: 0.505908835115363\n",
      "current test loss is: 1.0709675579713493\n",
      "training loss at 55000 is: 1.028878492368789\n",
      "training error at 55000 is: 0.498030388294879\n",
      "test error at 55000 is: 0.4926842993809792\n",
      "current test loss is: 1.1367964116683342\n",
      "training loss at 60000 is: 1.0289891126253483\n",
      "training error at 60000 is: 0.5014068655036579\n",
      "test error at 60000 is: 0.5075970737197524\n",
      "training error = 0.5014068655036579, test error = 0.5075970737197524\n",
      "Test error of Word2Vec is: 0.5075970737197524\n",
      "training error at 0 is: 0.4867754642656162\n",
      "test error at 0 is: 0.48733821046707937\n",
      "current test loss is: 0.999738123570703\n",
      "training loss at 5000 is: 0.5612210828779685\n",
      "training error at 5000 is: 0.13759144625773775\n",
      "test error at 5000 is: 0.27293190770962295\n",
      "current test loss is: 0.6662955693473487\n",
      "training loss at 10000 is: 0.27717902714480513\n",
      "training error at 10000 is: 0.0818795723128869\n",
      "test error at 10000 is: 0.2698368036015757\n",
      "current test loss is: 0.6286555539233215\n",
      "training loss at 15000 is: 0.18472110360485183\n",
      "training error at 15000 is: 0.04895891952729319\n",
      "test error at 15000 is: 0.2698368036015757\n",
      "current test loss is: 0.6223055759821329\n",
      "training loss at 20000 is: 0.13028510981452662\n",
      "training error at 20000 is: 0.03517163759144626\n",
      "test error at 20000 is: 0.2644907146876759\n",
      "current test loss is: 0.6195703232252848\n",
      "training loss at 25000 is: 0.0921285185834511\n",
      "training error at 25000 is: 0.023072594259988744\n",
      "test error at 25000 is: 0.26758581879572313\n",
      "current test loss is: 0.6238916447571948\n",
      "training loss at 30000 is: 0.07172774628108684\n",
      "training error at 30000 is: 0.016038266741699492\n",
      "test error at 30000 is: 0.27152504220596513\n",
      "current test loss is: 0.6301295042527775\n",
      "training loss at 35000 is: 0.04890267232449382\n",
      "training error at 35000 is: 0.012943162633652222\n",
      "test error at 35000 is: 0.2737760270118177\n",
      "current test loss is: 0.6378424243176427\n",
      "training loss at 40000 is: 0.043573440743966144\n",
      "training error at 40000 is: 0.009285312324141813\n",
      "test error at 40000 is: 0.2684299380979178\n",
      "current test loss is: 0.6363148384476661\n",
      "training loss at 45000 is: 0.031366253344800095\n",
      "training error at 45000 is: 0.006752954417557681\n",
      "test error at 45000 is: 0.27293190770962295\n",
      "current test loss is: 0.6410878452414557\n",
      "training loss at 50000 is: 0.02129921147870754\n",
      "training error at 50000 is: 0.005908835115362971\n",
      "test error at 50000 is: 0.2732132808103545\n",
      "training error = 0.005908835115362971, test error = 0.2732132808103545\n",
      "Test error of BOW is: 0.2732132808103545\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.6790697549093637\n",
      "training error at 5000 is: 0.09651097355092852\n",
      "test error at 5000 is: 0.419527293190771\n",
      "current test loss is: 0.9625689424832469\n",
      "training loss at 10000 is: 0.24573418169308503\n",
      "training error at 10000 is: 0.025886325267304444\n",
      "test error at 10000 is: 0.4088351153629713\n",
      "current test loss is: 0.9508749768725464\n",
      "training loss at 15000 is: 0.09499851063828908\n",
      "training error at 15000 is: 0.005627462014631401\n",
      "test error at 15000 is: 0.4060213843556556\n",
      "current test loss is: 0.9450124861331515\n",
      "training loss at 20000 is: 0.027636003921233287\n",
      "training error at 20000 is: 0.0025323579065841305\n",
      "test error at 20000 is: 0.40574001125492404\n",
      "current test loss is: 0.9441114849552815\n",
      "training loss at 25000 is: 0.012575774369795949\n",
      "training error at 25000 is: 0.0014068655036578502\n",
      "test error at 25000 is: 0.4034890264490715\n",
      "current test loss is: 0.9431248142667726\n",
      "training loss at 30000 is: 0.0057131872424393115\n",
      "training error at 30000 is: 0.0011254924029262803\n",
      "test error at 30000 is: 0.4040517726505346\n",
      "current test loss is: 0.9428784594386234\n",
      "training loss at 35000 is: 0.0031675187614116597\n",
      "training error at 35000 is: 0.0011254924029262803\n",
      "test error at 35000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426147690439293\n",
      "training loss at 40000 is: 0.00270057652908768\n",
      "training error at 40000 is: 0.0011254924029262803\n",
      "test error at 40000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426169499935265\n",
      "training loss at 45000 is: 0.004051530200755851\n",
      "training error at 45000 is: 0.0011254924029262803\n",
      "test error at 45000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 50000 is: 0.0036\n",
      "training error at 50000 is: 0.0011254924029262803\n",
      "test error at 50000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 55000 is: 0.004\n",
      "training error at 55000 is: 0.0011254924029262803\n",
      "test error at 55000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 60000 is: 0.0032\n",
      "training error at 60000 is: 0.0011254924029262803\n",
      "test error at 60000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 65000 is: 0.0024\n",
      "training error at 65000 is: 0.0011254924029262803\n",
      "test error at 65000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 70000 is: 0.0034\n",
      "training error at 70000 is: 0.0011254924029262803\n",
      "test error at 70000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 75000 is: 0.003\n",
      "training error at 75000 is: 0.0011254924029262803\n",
      "test error at 75000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 80000 is: 0.0038\n",
      "training error at 80000 is: 0.0011254924029262803\n",
      "test error at 80000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 85000 is: 0.0014\n",
      "training error at 85000 is: 0.0011254924029262803\n",
      "test error at 85000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 90000 is: 0.0042\n",
      "training error at 90000 is: 0.0011254924029262803\n",
      "test error at 90000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 95000 is: 0.0038\n",
      "training error at 95000 is: 0.0011254924029262803\n",
      "test error at 95000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 100000 is: 0.0024\n",
      "training error at 100000 is: 0.0011254924029262803\n",
      "test error at 100000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 105000 is: 0.0048\n",
      "training error at 105000 is: 0.0011254924029262803\n",
      "test error at 105000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 110000 is: 0.0034\n",
      "training error at 110000 is: 0.0011254924029262803\n",
      "test error at 110000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 115000 is: 0.0038\n",
      "training error at 115000 is: 0.0011254924029262803\n",
      "test error at 115000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 120000 is: 0.0022\n",
      "training error at 120000 is: 0.0011254924029262803\n",
      "test error at 120000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 125000 is: 0.005\n",
      "training error at 125000 is: 0.0011254924029262803\n",
      "test error at 125000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 130000 is: 0.0036\n",
      "training error at 130000 is: 0.0011254924029262803\n",
      "test error at 130000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 135000 is: 0.0042\n",
      "training error at 135000 is: 0.0011254924029262803\n",
      "test error at 135000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 140000 is: 0.0034\n",
      "training error at 140000 is: 0.0011254924029262803\n",
      "test error at 140000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 145000 is: 0.0046\n",
      "training error at 145000 is: 0.0011254924029262803\n",
      "test error at 145000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 150000 is: 0.0022\n",
      "training error at 150000 is: 0.0011254924029262803\n",
      "test error at 150000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 155000 is: 0.0032\n",
      "training error at 155000 is: 0.0011254924029262803\n",
      "test error at 155000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 160000 is: 0.0022\n",
      "training error at 160000 is: 0.0011254924029262803\n",
      "test error at 160000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 165000 is: 0.0026\n",
      "training error at 165000 is: 0.0011254924029262803\n",
      "test error at 165000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 170000 is: 0.0024\n",
      "training error at 170000 is: 0.0011254924029262803\n",
      "test error at 170000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 175000 is: 0.0036\n",
      "training error at 175000 is: 0.0011254924029262803\n",
      "test error at 175000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 180000 is: 0.0024\n",
      "training error at 180000 is: 0.0011254924029262803\n",
      "test error at 180000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 185000 is: 0.0036\n",
      "training error at 185000 is: 0.0011254924029262803\n",
      "test error at 185000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 190000 is: 0.0032\n",
      "training error at 190000 is: 0.0011254924029262803\n",
      "test error at 190000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training loss at 195000 is: 0.002\n",
      "training error at 195000 is: 0.0011254924029262803\n",
      "test error at 195000 is: 0.4034890264490715\n",
      "current test loss is: 0.9426233421874873\n",
      "training error = 0.0011254924029262803, test error = 0.4034890264490715\n",
      "Test error of Bigram is: 0.4034890264490715\n",
      "training error at 0 is: 0.49774901519414744\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.0\n",
      "training loss at 5000 is: 0.6912945056768237\n",
      "training error at 5000 is: 0.1221159257175014\n",
      "test error at 5000 is: 0.48368036015756893\n",
      "current test loss is: 0.997580806523995\n",
      "training loss at 10000 is: 0.2782499509588564\n",
      "training error at 10000 is: 0.03714124929656725\n",
      "test error at 10000 is: 0.4819921215531795\n",
      "current test loss is: 0.9964202484313522\n",
      "training loss at 15000 is: 0.10795974455778273\n",
      "training error at 15000 is: 0.018289251547552055\n",
      "test error at 15000 is: 0.4800225098480585\n",
      "current test loss is: 0.9957400367123471\n",
      "training loss at 20000 is: 0.0486158793577091\n",
      "training error at 20000 is: 0.011254924029262802\n",
      "test error at 20000 is: 0.4800225098480585\n",
      "current test loss is: 0.9954070855209112\n",
      "training loss at 25000 is: 0.03354662984308861\n",
      "training error at 25000 is: 0.009285312324141813\n",
      "test error at 25000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953417142837003\n",
      "training loss at 30000 is: 0.02186876827178887\n",
      "training error at 30000 is: 0.009285312324141813\n",
      "test error at 30000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953386383766621\n",
      "training loss at 35000 is: 0.02165822208516735\n",
      "training error at 35000 is: 0.009285312324141813\n",
      "test error at 35000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953375452899005\n",
      "training loss at 40000 is: 0.0237\n",
      "training error at 40000 is: 0.009285312324141813\n",
      "test error at 40000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 45000 is: 0.0234\n",
      "training error at 45000 is: 0.009285312324141813\n",
      "test error at 45000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 50000 is: 0.023\n",
      "training error at 50000 is: 0.009285312324141813\n",
      "test error at 50000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 55000 is: 0.0242\n",
      "training error at 55000 is: 0.009285312324141813\n",
      "test error at 55000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 60000 is: 0.0198\n",
      "training error at 60000 is: 0.009285312324141813\n",
      "test error at 60000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 65000 is: 0.0208\n",
      "training error at 65000 is: 0.009285312324141813\n",
      "test error at 65000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 70000 is: 0.0244\n",
      "training error at 70000 is: 0.009285312324141813\n",
      "test error at 70000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 75000 is: 0.022\n",
      "training error at 75000 is: 0.009285312324141813\n",
      "test error at 75000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 80000 is: 0.0208\n",
      "training error at 80000 is: 0.009285312324141813\n",
      "test error at 80000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 85000 is: 0.0198\n",
      "training error at 85000 is: 0.009285312324141813\n",
      "test error at 85000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 90000 is: 0.0234\n",
      "training error at 90000 is: 0.009285312324141813\n",
      "test error at 90000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 95000 is: 0.0218\n",
      "training error at 95000 is: 0.009285312324141813\n",
      "test error at 95000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 100000 is: 0.0202\n",
      "training error at 100000 is: 0.009285312324141813\n",
      "test error at 100000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 105000 is: 0.02\n",
      "training error at 105000 is: 0.009285312324141813\n",
      "test error at 105000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 110000 is: 0.0198\n",
      "training error at 110000 is: 0.009285312324141813\n",
      "test error at 110000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 115000 is: 0.0206\n",
      "training error at 115000 is: 0.009285312324141813\n",
      "test error at 115000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 120000 is: 0.0254\n",
      "training error at 120000 is: 0.009285312324141813\n",
      "test error at 120000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 125000 is: 0.0228\n",
      "training error at 125000 is: 0.009285312324141813\n",
      "test error at 125000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 130000 is: 0.023\n",
      "training error at 130000 is: 0.009285312324141813\n",
      "test error at 130000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at 135000 is: 0.0216\n",
      "training error at 135000 is: 0.009285312324141813\n",
      "test error at 135000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 140000 is: 0.021\n",
      "training error at 140000 is: 0.009285312324141813\n",
      "test error at 140000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 145000 is: 0.0224\n",
      "training error at 145000 is: 0.009285312324141813\n",
      "test error at 145000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 150000 is: 0.0212\n",
      "training error at 150000 is: 0.009285312324141813\n",
      "test error at 150000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 155000 is: 0.0256\n",
      "training error at 155000 is: 0.009285312324141813\n",
      "test error at 155000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 160000 is: 0.022\n",
      "training error at 160000 is: 0.009285312324141813\n",
      "test error at 160000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 165000 is: 0.0214\n",
      "training error at 165000 is: 0.009285312324141813\n",
      "test error at 165000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 170000 is: 0.0264\n",
      "training error at 170000 is: 0.009285312324141813\n",
      "test error at 170000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 175000 is: 0.025\n",
      "training error at 175000 is: 0.009285312324141813\n",
      "test error at 175000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 180000 is: 0.0206\n",
      "training error at 180000 is: 0.009285312324141813\n",
      "test error at 180000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 185000 is: 0.021\n",
      "training error at 185000 is: 0.009285312324141813\n",
      "test error at 185000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 190000 is: 0.0216\n",
      "training error at 190000 is: 0.009285312324141813\n",
      "test error at 190000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training loss at 195000 is: 0.0198\n",
      "training error at 195000 is: 0.009285312324141813\n",
      "test error at 195000 is: 0.47974113674732694\n",
      "current test loss is: 0.9953310408579308\n",
      "training error = 0.009285312324141813, test error = 0.47974113674732694\n",
      "Test error of Trigram is: 0.47974113674732694\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.000105266946403\n",
      "training loss at 5000 is: 0.6006418444180693\n",
      "training error at 5000 is: 0.0723128868880135\n",
      "test error at 5000 is: 0.27293190770962295\n",
      "current test loss is: 0.8009931500669475\n",
      "training loss at 10000 is: 0.21112302671887145\n",
      "training error at 10000 is: 0.021102982554867755\n",
      "test error at 10000 is: 0.2583005064715813\n",
      "current test loss is: 0.7526179241706634\n",
      "training loss at 15000 is: 0.07154297169902539\n",
      "training error at 15000 is: 0.007315700619020821\n",
      "test error at 15000 is: 0.2563308947664603\n",
      "current test loss is: 0.7409081314698891\n",
      "training loss at 20000 is: 0.029152380085162268\n",
      "training error at 20000 is: 0.0016882386043894203\n",
      "test error at 20000 is: 0.2535171637591446\n",
      "current test loss is: 0.7368190841037218\n",
      "training loss at 25000 is: 0.01004446789931276\n",
      "training error at 25000 is: 0.0002813731007315701\n",
      "test error at 25000 is: 0.25267304445694994\n",
      "current test loss is: 0.7370888353276898\n",
      "training loss at 30000 is: 0.0031169652228053343\n",
      "training error at 30000 is: 0.0\n",
      "test error at 30000 is: 0.2535171637591446\n",
      "current test loss is: 0.7356602160108411\n",
      "training loss at 35000 is: 0.0005855527320620239\n",
      "training error at 35000 is: 0.0\n",
      "test error at 35000 is: 0.25407990996060775\n",
      "current test loss is: 0.7357122432739183\n",
      "training loss at 40000 is: 0.00029572681376190027\n",
      "training error at 40000 is: 0.0\n",
      "test error at 40000 is: 0.25211029825548675\n",
      "current test loss is: 0.735665929766035\n",
      "training loss at 45000 is: 0.0010420866447455523\n",
      "training error at 45000 is: 0.0\n",
      "test error at 45000 is: 0.2515475520540236\n",
      "current test loss is: 0.7354491393630338\n",
      "training loss at 50000 is: 0.0006031329230167518\n",
      "training error at 50000 is: 0.0\n",
      "test error at 50000 is: 0.2518289251547552\n",
      "current test loss is: 0.7354718686844572\n",
      "training loss at 55000 is: 0.0004008635725739511\n",
      "training error at 55000 is: 0.0\n",
      "test error at 55000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 60000 is: 0.0004\n",
      "training error at 60000 is: 0.0\n",
      "test error at 60000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 65000 is: 0.0002\n",
      "training error at 65000 is: 0.0\n",
      "test error at 65000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 70000 is: 0.0\n",
      "test error at 70000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 75000 is: 0.0\n",
      "test error at 75000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 80000 is: 0.0002\n",
      "training error at 80000 is: 0.0\n",
      "test error at 80000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 85000 is: 0.0004\n",
      "training error at 85000 is: 0.0\n",
      "test error at 85000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 90000 is: 0.0004\n",
      "training error at 90000 is: 0.0\n",
      "test error at 90000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 95000 is: 0.0002\n",
      "training error at 95000 is: 0.0\n",
      "test error at 95000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 100000 is: 0.0008\n",
      "training error at 100000 is: 0.0\n",
      "test error at 100000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 105000 is: 0.0004\n",
      "training error at 105000 is: 0.0\n",
      "test error at 105000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 110000 is: 0.0004\n",
      "training error at 110000 is: 0.0\n",
      "test error at 110000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 115000 is: 0.0\n",
      "test error at 115000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 120000 is: 0.0002\n",
      "training error at 120000 is: 0.0\n",
      "test error at 120000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 125000 is: 0.0002\n",
      "training error at 125000 is: 0.0\n",
      "test error at 125000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 130000 is: 0.0002\n",
      "training error at 130000 is: 0.0\n",
      "test error at 130000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 135000 is: 0.0\n",
      "test error at 135000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 140000 is: 0.0\n",
      "test error at 140000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 145000 is: 0.0006\n",
      "training error at 145000 is: 0.0\n",
      "test error at 145000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 150000 is: 0.0\n",
      "test error at 150000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 155000 is: 0.0002\n",
      "training error at 155000 is: 0.0\n",
      "test error at 155000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 160000 is: 0.0\n",
      "test error at 160000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 165000 is: 0.0002\n",
      "training error at 165000 is: 0.0\n",
      "test error at 165000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 170000 is: 0.0004\n",
      "training error at 170000 is: 0.0\n",
      "test error at 170000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 175000 is: 0.0\n",
      "test error at 175000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training error at 180000 is: 0.0\n",
      "test error at 180000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 185000 is: 0.0004\n",
      "training error at 185000 is: 0.0\n",
      "test error at 185000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 190000 is: 0.0004\n",
      "training error at 190000 is: 0.0\n",
      "test error at 190000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n",
      "training loss at 195000 is: 0.0002\n",
      "training error at 195000 is: 0.0\n",
      "test error at 195000 is: 0.2515475520540236\n",
      "current test loss is: 0.7353907290489928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error = 0.0, test error = 0.2515475520540236\n",
      "Test error of Combo is: 0.2515475520540236\n",
      "training error at 0 is: 0.498030388294879\n",
      "test error at 0 is: 0.4926842993809792\n",
      "current test loss is: 1.9215841201725035\n",
      "training loss at 5000 is: 1.5024155655967946\n",
      "training error at 5000 is: 0.5016882386043894\n",
      "test error at 5000 is: 0.5073157006190209\n",
      "current test loss is: 2.217436577008844\n",
      "training loss at 10000 is: 1.5020401036817252\n",
      "training error at 10000 is: 0.5014068655036579\n",
      "test error at 10000 is: 0.5073157006190209\n",
      "current test loss is: 1.7311502276747808\n",
      "training loss at 15000 is: 1.508093760219434\n",
      "training error at 15000 is: 0.498030388294879\n",
      "test error at 15000 is: 0.4926842993809792\n",
      "current test loss is: 1.9136551631768761\n",
      "training loss at 20000 is: 1.488958456092407\n",
      "training error at 20000 is: 0.4395047833427124\n",
      "test error at 20000 is: 0.43528418683173886\n",
      "current test loss is: 0.9230325328220443\n",
      "training loss at 25000 is: 1.4677562613963648\n",
      "training error at 25000 is: 0.498030388294879\n",
      "test error at 25000 is: 0.4926842993809792\n",
      "current test loss is: 1.511712999940897\n",
      "training loss at 30000 is: 1.4791079474108952\n",
      "training error at 30000 is: 0.498030388294879\n",
      "test error at 30000 is: 0.4926842993809792\n",
      "current test loss is: 1.9137038910416817\n",
      "training loss at 35000 is: 1.49385408446793\n",
      "training error at 35000 is: 0.498030388294879\n",
      "test error at 35000 is: 0.4926842993809792\n",
      "current test loss is: 1.9266947296192634\n",
      "training loss at 40000 is: 1.4690708027681285\n",
      "training error at 40000 is: 0.5016882386043894\n",
      "test error at 40000 is: 0.5073157006190209\n",
      "current test loss is: 2.107694871023707\n",
      "training loss at 45000 is: 1.4824445200714442\n",
      "training error at 45000 is: 0.498030388294879\n",
      "test error at 45000 is: 0.4926842993809792\n",
      "current test loss is: 1.6937831763184863\n",
      "training loss at 50000 is: 1.4405309856375608\n",
      "training error at 50000 is: 0.5016882386043894\n",
      "test error at 50000 is: 0.5073157006190209\n",
      "training error = 0.5016882386043894, test error = 0.5073157006190209\n",
      "Test error of Word2Vec is: 0.5073157006190209\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = readExamples('data/data_rt.train')\n",
    "train_new = []\n",
    "for example in train_set:\n",
    "    text = normalize_string(example[0])\n",
    "    label = example[1]\n",
    "    train_new.append((text, label))\n",
    "\n",
    "train_corpus = [example[0] for example in train_new]\n",
    "train_label = [example[1] for example in train_new]\n",
    "    \n",
    "test_set = readExamples('data/data_rt.test')\n",
    "test_new = []\n",
    "for example in test_set:\n",
    "    text = normalize_string(example[0])\n",
    "    label = example[1]\n",
    "    test_new.append((text, label))\n",
    "    \n",
    "test_corpus = [example[0] for example in test_new]\n",
    "test_label = [example[1] for example in test_new]\n",
    "    \n",
    "train_num = len(train_corpus)\n",
    "#mode_list = ['BOW', 'Bigram', 'Trigram', 'Combo', 'Word2Vec', 'Glove']\n",
    "mode_list = ['BOW', 'Bigram', 'Trigram', 'Combo', 'Word2Vec']\n",
    "combo_embed = extractFeatures(train_corpus + test_corpus, mode_list[1])\n",
    "train_embed = combo_embed[:train_num]\n",
    "test_embed = combo_embed[train_num:]\n",
    "    #train_data, val_data, train_l, val_l = train_test_split(train_embed, train_label, test_size = 0.1, random_state = 31)\n",
    "\n",
    "min_error = 1.0\n",
    "iters_list = [200000]\n",
    "learning_rate = [0.02, 0.1, 0.5]\n",
    "reg_list = [0.0]\n",
    "best_w = None\n",
    "best_b = None\n",
    "best_combo = None\n",
    "for iters in iters_list:\n",
    "    for lr in learning_rate:\n",
    "        for reg in reg_list:\n",
    "            for mode in mode_list:\n",
    "                combo_embed = extractFeatures(train_corpus + test_corpus, mode)\n",
    "                train_embed = combo_embed[:train_num]\n",
    "                test_embed = combo_embed[train_num:]\n",
    "                w, b, testError = TestModel(iters, lr, reg, mode, train_embed, test_embed, train_label, test_label)\n",
    "                print('Test error of {} is: {}'.format(mode, testError))\n",
    "                    \n",
    "                #if valError < min_error:\n",
    "                    #best_w = w\n",
    "                    #best_b = b\n",
    "                    #best_combo = [iters, lr, reg]\n",
    "#print('Best hyper combo is: ')\n",
    "#print(best_combo)\n",
    "\n",
    "#testError = evaluatePredictor(test_embed, test_label, best_w, best_b)\n",
    "#print('Test error is: {}'.format(testError))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
